T   = Notes + Revision of Questions
F   = ND 3 + 1SP
S   = ND 3 + 1SP
S   
M

--------------------------------------------------------------------------

CoudFront 
Source content can  be S3,EC2, ELB and external websites
Integrate with Shield and WAF
TTL default = 24hrs
Http to Https
RTMP

Signed URL = apps download, shared content to premium user, one URL one file
Singed cookie = key values airs, multiple files, no URL change , one cookie many files

CloudFront is great for static content that must be available everywhere
CloudFront Geo restriction for restrict contents to users in certain countries

CloudFtront to EC2 (must be public) with IAM Role , SG of EC2 allow all ips of CF
CloudFtront to ALB (must be public) with IAM Role , EC2 private, SG of EC2 allow SG of ALB
CloudFront to S3, OAI , only CF can use S3 , bucket policy allow S3 only to speail OAI user

S3 signed URL are not efficient for global access

Client --> CloudFront --> ALB --> ASG (EC2) --> Elastic File System (software updates)
---------------------------------------------------------------------------------------

AWS Global Accelerator uses Anycast , 2 Anycast IP are created for your application
only 2 external ip need to be whitelisted
Good for non http use cases TCP ,  like gaming(UDP),IOT(MQTT) or voice over IP
not Free

S3 Cross Region replication is great for dynamic content that needs to be available at low latency in few Regions
S3 CRR allows you to replicate the data from one bucket in a region to another bucket in another region
Global Accelerator will provide us with the two static IP
CloudFront Signed URL are commonly used to distribute paid content 

----------------------------------------------------------------------
SQS = Pull model
max message size = 256KB

Standard Queue = unlimited throughput, can duplicate
FIFO = ordered, exactly one msg , 300 msg/s , batch 10 msg/operation,3000 msg/sec
 .fifo ,msg  with message group id

SQS usues TargetTracking for AG

Visibility tineout means that the message needs to be processed in 30 sec
default = 30 sec - > 12hrs
if visibility timeout is too high , and consumer crash, re-processing takes much time
if visibility timeout is too low , we may get duplicates

Delivery Delay
delays a message (consumer don't see it immediately) up to 15 mins 
if your consumers need additional time to process messages, you can delay each new message coming to the queue

 Message Retention period
*default = 4 days
*min 60 secs  ie 
*max 14 days

MaxReceiveCount
Max no. of failures in processing a msg to a single Dead letter queue

Reduce no. of API calls to SQS
use Long polling ie WaitTimeSeconds up to 20 seconds

use SQS Access Policies to allow othe servies to write SQS API, cross access

SQS FIFO if u don't use a Group ID, messages are consumed in the order they are sent, with only one consumer

Group Id is similar to partition key
the more group id , the more consumer


-----------------------------------------------------------
SNS

SQS,http/https,Lambda,Emails,SMS msg,Mobile notifications
 can configure retry policy
SNS can't send message to SQS FIFO queues

SNS -> multiple SQS : Fan Out


MQ
** use open protocol as MQTT, AMQP,OpenWire,WSS,STOMP
Amazon MQ = SQS + SNS but with restricted scalability


--------------------------------------------------------
Kinesis (alternative to kafka) not in free tier
** great for "real-time" big data, clickstreams
Data is automatically replicated to 3 AZ
aysnc 

 
1)Kinesis Data Streaming
ETL, Streaming ,ability to reporcess and repay
Immutability: data inserted in Kinesis can't be deleted

one stream is made of many different shards
Billing is per shard/partition provisioned 
Records are ordered  per shard

1 MB/s for Write per shard
2 MB/s for Read per shard

** Choose a partition key ie user_id that is highly distributed
so that request will not always goes to a particular shard and overwhelmed it (hot partition)
* VPC endpoints available for Kinesis to access within VPC
use Batching with PutRecords to reduce cost and increase throughput


2) AWS Kinesis Data Analytics
**  perform Real-time (200 ms) analytics on stream using SQL
* Data coming via Kinesis Firehose and Kinesis Data Streams

3) AWS Kinesis Data Firehose (Serverless)
Data transform using Lambda
* Managed service, Data Ingestion for streaming data
**  store  to S3,Elastic search ,Redshift and splunk
near real time (1 min)


Lambda Supports
Node.js,python,Java 8,C#,Golang,powershell,Ruby,Custom Runtime API (rust)
Docker is not for AWS lambda,

*** 1) memory allocation : 128 MB - 3008 MB (64 MB increment)
*** 2) Max execution time : 900 secs or 15 mins
*** 3) environment variables: 4KB
*** 4) disk capacity : 512 MB in /tmp
*** 5) concurrency executions : 1000 (can be increase)

1) deployment size : 50 MB compressed
2) un compressed: 250 MB
3) can use /tmp to load other files at startup


-----------------------------------------------------------------------------
API Gateway (Serverless)
web sockets support
handle request throttling
Can  Run Multiple Versions of API and multiple environments
Lambda + API Gateway = No infra to manage
Caching for API call with TTL
Quota = total no of request in a month
Canary Deployment: sent a % request to a no. of users


3 ways to deploy API Gateway

1) Edge-Optimized (default) 
For global clients
requests are routed through CloudFront edge locations 
API gateway still lives in only one region

2) Regional
for clients within the same region
more control over caching

3) Private
can only be accessed from your VPC using VPC endpoint ENI
use response policy for access

HTTP API is new version of REST API


API Gateway - Security 

1) IAM Permissions (sig v4)
create an IAM policy  and attach it to User/Role
** User call API and provides  IAM credentials in header with "sig v4" capability to API gateway
which call IAM policy to check
create a signature using AWS secret access key and send it with API request
if ur users belong to same AWS Account

2) Lambda Authorizer / Custom Authorizer
Implement a lambda function to authenticate (JWT,OAtuh) and return AMI policies
** great for 3rd party token, OATh/SAML/3rd party type of authentication
User call API wit token --> API gateway -> pass it to Lambda Authorizer -> Evaluate token and return IAM policy


 Amazon Cognito
authenticate mobile and web-apps


a) Cognito - USER POOLS  (CUP)
only for authentication
Integrate with API Gateway
* manage your own user pool (can be backed by Facebook, google etc)
* Creates a serverless database of user for your mobile app

Client connect to Cognito user pools which authenticate and retrieve token
which application pass it to the API gateway and API gateway communicate with Cognito user pool
** Can  enabled Federated identity in user pool

b) Cognito - IDENTITY POOLS (FEDERATED IDENTITY)
 Goal is to provide direct access to AWS services from client side
Provide temporary access to write to S3 buckets using FB login

 identity pool validates token from IDP via STS and creates temp access keys,secret key and session token


-----------
Lambda@Edge
running lambda functions at end location
deploy  lambda functions alongside your CloudFtont CDN
request filtering 
Bot mitigation 

*  only supports Node.js and Python
* No free tier and more expensive than lambda


ServerLess Application Model (SAM)
 to test serverless projects with lambda,API gateway and dynaDB in local
its a open source, yaml

* Viewer request- trigger when request arrive at edge location
* Origin request- just before sending request to origin when  obj is not in cache
* Origin response-After edge loc receive response back from origin
* Viewer Response: just before response is send  back from edge to user

---------------------------------AWS Step Functions (Serverless)--(Latest)-----------------------------------------------------
*Build serverless visual workflow to orchestrate your Lambda functions
Represent flow as a JSON state machine
build workflows as a series of steps with Retry and invoke multiple aws services 
1 year duration
Integrate with API GW,EC2, ECS and on-primise
No External interventoin allowed
Not worked when child process that return values to parent processes

---------------------------AWS Simple Workflow Service (SWF) (OLD)-------------

for complex orchestration 
 Code runs on EC2 (not serverless)
Has built in human intervention step


--------------------------------------------------------------------------
** Big Data Ingestion Pipeline
should be fully serverless

IOT Devices -> AWS IoT Core -> Kinesis Data Stream -> Kinesis Firehose -> S3 ingestion bucket
S3 ingestion bucket -> Lambda -> Athena to Query bucket data -> S3 storage for reporting
-> Aws QuickSight (AWS business intelligence tool)

*  Streams enable DynamoDB to get a changelog and use that changelog to replicate data across regions
** SQS allows you to retain messages for days and process them later, while we take down our EC2 instances
** CloudFront Signed URL have security including IP restriction

------------------------------------------------------------------------------------------------------------------
** Apply S3 policy may take some times as it replicates
** A role can be assigned to multiple EC2 instances
** But each EC2 instance can have only one role
** You can't attach EC2 IAM roles to on premise servers

We can also leverage AWS Policy Simulator to test the policy
you can retrieve IAM role name from metadata but CANNOT retrieve IAM policy

-----------------------------------------------

Cloud Watch Metrics
**  provides metrics for each service in AWS
Metric is a variable to monitor (CPU Utilization, Networking)
Metric belongs to a namespace(category)
**  Dimension  is an attribute of a metric (Instance id, environment)
** Up to 10 dimensions per metric
Metric have timestamps
Metric resolution
** standard: 1 min

** The number of instances in an ASG cannot go below the minimum, even if the alarm would in theory trigger an instance termination

---------------------------------------------------------------
CloudTrail (not free)
**  Provides governance , compliance and audit for your AWS Account
Enables you to assess, audit, and evaluate the configuration of your AWS resources
who made the request , what action, what parameter, what end result
CloudTrail is enabled by default
its like a change log 
 If a resource is delete in AWS, look into CloudTrail First
deliver log file to S3(default)

Multi Region Trail = One trail of all AWS Regions
Single Region Trail = Only event from one specific region

----------------AWS Config-------------------------------------------
complete inventory of our AWS resources
how resource was configured at any time
history file to s3 bucket every 6 hour
* AWS config is a per-region service
Can setup auto remediation for each rule (lambda functions with custom rules) (delete elastic IP which is not used, stop ec2 instance without a TAG)

Config rules are not free, $2 per active rule per region per month

alb-HTTP-HTTPS-redirection-check
ebs-optimized-instance 
ec2-instance-no-public-ip
encrypted-volumes
eip-restricked
restricted-ssh

ensure SSL certificate is always assigned t LB for compliance
-------------------------CloudWatch ---------------------------------------

AWS CloudWatch is all about Monitoring and observability service

 Dashboards are global

-CloudWatch Alarms (Based on metrics)-
 CPU utilization
Amazon ELB request latency
Amazon DynamoDB table throughput,
Amazon SQS queue length, or even the charges on your AWS bill

EC2Instnace recovery
setup a cloudwatch alarm (StatisCheckFailed_system) that when trigger
do instance recovery 
same Private IP, Public IP, ElatiC IP, metadata and placement group

CLoudWatch logs
monitor for patterns in logs and trigger events based on them 
 can define log expiration policies 
to send logs to CloudWatch, make sure IAM permission are correct
Amazon CloudWatch does NOT have access to operating system metrics like memory consumption

Cloudwatch Insights
write queries and get actionable insight from your logs

CloudWatch Events  (related to resources)
near read-time stream of systems events that describe changes in AWS resources (JSON)
trigger when someone stop an ec2 instance
call lambda when EC2 starts
notify SNS topic when auto scaling event happs
Also you can schedule events , use unix cron syntax

AWS CloudTrail only records API calls for future references But Cloud Watch events allow you to take actions

Cloudwatch SeviceLens 
monitors issues with Microservice based applications

X-Ray is used to trace your application
X-Rays traces a request between API Gateway and Lambda functions

Cloudwatch Logs Agents
** Installed on EC2 to move logs from servers to CloudWatch logs
Can also installed on premise server

CloudWatch Unified Agent (Latest version)
logs at lot more granularity level
Collect additional system level metrics such as Ram, Processes

DR

1) Pilot Light (for critical systems)
* a small version of application is always running in cloud
ie RDS in data replication with on premise database is up

2) Warm Standby (Full system with  minimize size)
* Full system is up and running in Cloud but at minimize size

3)Multi Site/ Hot Site Approach (v. expensive)
Full system is up and running in Cloud as of on premise
v expensive 

4) Backup and Restore
lowest cost


Backups
EBS snapshots, RDS automated backups/snapshots

For HA
* use Route53 to migrate DNS over from region to region
RDS multi AZ, Elastic cache,EFS, S3

For Replication
RDS replication, Aurora GDB

------------------------Database Migration Service DMS ----------------------------
 Migrate databases from on-premise to AWS
*Source database remains available during migration
 * Must create EC2 instance (running DMS)

consolidate multiple DB into a single target database
DMS is for smaller workloads (less than 10TB)
* continuous data replication for DR


------AWS Schema Conversion Tool --------SCT-------
*  It is a part of DMS
*  preferred option for migrating data warehouse data to Redshift
SCT is preferred for large data warehouse workloads (migration to Redshift)


AWS Server Migration Service (SMS)
*  increment replication of on-premise live servers to AWS
* AWS Server Migration Service (SMS) is an agent less service which makes it easier and faster for you to migrate thousands of on-premises workloads to AWS
Transfer Large amount of data from On-Premise to AWS
200 TB of data , with 100 MB/S internet speed


1)  Over the internet / site to site VPN
immediate to setup

2) Over Direct Connect DX 1 Gbps
long time setup (over a month)

3) Over snowball
will order 2-3 snowballs in parallel
takes 1 week to end to end transfer

4) for on-going replication
site-to-site VPN or DX with DMS or DataSync

AWS CodeBuild (Continuous Integration)
Build and test code with continuous scaling. AWS CodeBuild is a fully managed build service that compiles source code, runs tests, and produces software packages that are ready to deploy. With CodeBuild, you don’t need to provision, manage, and scale your own build servers;
* CodeBuild is an alternative to Jenkins

AWS CodeDeploy (Continuous Delivery)
is a service that automates code deployments to Amazon EC2 instances. AWS CodeDeploy makes it easier for you to rapidly release new features, helps you avoid downtime during deployment, and handles the complexity of updating your applications.
AWS CodeDeploy is a deployment service that automates application deployments to Amazon EC2 instances, on-premises instances, or serverless Lambda function.

Orchestration
AWS CodePipeline

Infrastructure Provisioning
 provisioned compute,db,storage,networking
AWS service: CloudFormation

Configuration management
Install right software and tools on provisioned resources
AWS Service: OpsWorks ( Chef and Puppet to automate )

* CloudFormaion handles dependencies
eg. first VPC then subnets and then db
* Automatic Rollback
* Free to use , pay for resources provisioned
Templates have to be uploaded in S3 and referenced in CloudFormation
 Deleting a stack will delete all its artifacts Except DelitoinPolicy set to "Retain" or  Termination policy for the entire stack is Enabled

"Resources" only Mandatory component in CF Template

Elastic Beanstalk
like a pre packaged cloud-formation template with a user interface
and in background cloud-formation template is created and executed

A stack is a collection of AWS resources that you can manage as a single unit.
 A stack, for instance, can include all the resources required to run a web application, such as a web server, a database, and networking rules. If you no longer require that web application, you can simply delete the stack, and all of its related resources are deleted
. If a resource cannot be created, AWS CloudFormation rolls the stack back and automatically deletes any resources that were created. 


A template is a declaration of the AWS resources that make up a stack

CF Stacksets enable you to do multi-account and cross-region deployments
Nested stacks make the process of updating stack easier

To declare same resources to multiple CF templates, use Nested stacks
create separate templates for these resources and reference them on the other template

A stack set is a regional resource. If you create a stack set in one Region, you cannot see it or change it in other Regions.

You can control RAM/CPU allocations to your containers

ECS is an AWS proprietary technology, whereas EKS based on Kubernetes which is open source

AWS Elastic Container Service ECS (helps to run docker containers on EC2)
Need to create a cluster of EC2 instance managed by ECS for Microservice
ECS is a fully managed service
Small deployment
When you’re looking for a solution that combines simplicity and availability, and you want to have advanced control over your infrastructure, then ECS is the right choice for you.

EKS is subjected to an additional cost of running Master nodes (cluster)
Large or hybrid deployments 
EKS is a bit trickier and requires a more complex deployment configuration and expertise
If you already have containers running on Kubernetes or want an advanced orchestration solution with more compatibility, you should use Amazon EKS
* Its an Alternative to ECS, similar goal but different API 
EKS supports EC2 and Fargate


AWS Fargate (No free tier): Serverless version of AWS ECS


ECS Tasks
A task definition is a blueprint for your application (container details)

ECS  IAM Roles
roles assigned to tasks to interact with AWS

ECS Service
A service allows you to run and maintain a specified number 
(the "desired count") of simultaneous instances of a task definition in an ECS cluster.

* For Fargate
No EC2 instance created
LB is created
Target Group is created
* To scale just increase task no.

Task execution IAM role (permission to pull container images)

A existing task deification can't be changed
* A tasks has IP and container details


ECS Cluster
Groping of one or more container instances (EC2 instances) when u run your tasks

ECS -> ALB (Direct Integration Feature)

** Dynamic host port mapping  (multiple task from the same service allowed per EC2 container)
** This allow you to run multiple instances of the same application on the same EC2 machine
path based routing multiple services can use same listener port on same ALB and be routed based the path

ECS instance (pull images) -> ECR - IAM (for access)
EC2 having ECS agent and running

Not to access ECS  service, EC2 instance should have a IAM role


IAM task roles to be define, Each ECS task should have
ECS IAM task role to perform their API calls

Elastic MapReduce  (EMR)
Managed Hadoop service with High availability and durability
EMR helps creating Hadoop cluster (Big data)  with 100s of EC2 instances
** EMR give access to underlying OS ie u can ssh into it
web service for big data processing

HDFS
Data storage = EBS or Instance Store (data can lost if instance down)

 EMRFS ( Elastic MapReduce File System)
Data Storage = S3
Infrequent big data jobs (ad-hoc queries)

Amazon S3 is a flat object store and commonly referred to these days as a “data lake”.
Amazon Redshift is a relational, OLAP-style database. It’s a data warehouse built for the cloud, to run the most complex analytical workloads in standard SQL. 
Amazon Redshift Spectrum is a feature of Amazon Redshift. Spectrum is a serverless query processing engine that allows to join data that sits in Amazon S3 with data in Amazon Redshift

If execution speed and for queries and transformations is of essence, then using Amazon Redshift is the way to go.
The trade-off is that Redshift Spectrum queries do run slower than queries in an Amazon Redshift cluster, mainly because of data movement between S3 and the cluster.

Amazon Aurora to sell tickets
Amazon Redshift to store short-term historical data to analyze how many tickets they’ve sold
Amazon S3 for cheaper storage of all long-term historical ticket data
Amazon Redshift Spectrum to join long-term historical data in S3 with short-term historical data in Amazon Redshift, e.g. for multi-year comparisons from ticket sales in a current year vs. ticket sales from 10 years ago.
Amazon Athena for quick ad-hoc querying of data in S3, e.g. to answer a single-year question about ticket sales that requires data that only sits in S3, e.g. “how many tickets did we sell in July 10 years ago?” 

AWS Glue (Serverless)
** Run ETL jobs using Spark
Source:Aurora,RDS,Redshift and S3
Automated Code  Generation
Crawls data sources and identify data formats (Schema Inference)


------------------------------AWS OpsWorks-----------------------------------------------------------------
is a Configuration Management Tool
** Managed service based on Chef and Puppet
Its an alternative to AWS SSM (AWS Systems Manager)
is an AWS service that you can use to view and control your infrastructure on AWS)
eg. make a change across 100 server both on premise and on cloud

---------------------------------------------AWS Elastic Transcoder--------------------------------------------------------------------------
****  Fully managed service to convert media files stored in S3 into various formats
create WebM video,Mp3 audio or animated Gif

For all other video processing use cases, recommanded to use Element MediaConvert

-------------------------------------------------AWS Workspaces-------------------------------------------------------------------------
Desktop as a Service (DaaS), MANAGED , Secure Cloud Desktop
*** Replacement for VDI (virtual Desktop infrastructure)

-----AWS AppSync-- latest
* Store and Sync data across mobile and web apps in real time
** based on GraphQL (FB framework, mobile technology ) get data from multiple API
Offline data synchronization (replaces Congnito Sync)


1) OPERATIONAL EXCELLENCE PILAR
Ability to run and monitor systems 

a) PREPARE: for failure  AWS Config for standard, CF
b) OPERATE: gather data and metrics CW,CT,VPC flow logs,X-Rays
c) EVLOVE: Get Intelligence using CF, Elastic Search


2) SECURITY PILAR

a. PRINCIPLE OF LEAST PRIVILEGE for least time
b. SECURITY IN DEPTH - Apply security in all layers
c. PROTECTING DATA AT REST
d. PROTECTING  DATA IN TRANSIT	
e: Detect Threats  (GuadDurty to detect threats, AWS Organization to centralize security policies) 


3) RELIABILITY PILAR
 how quickly you recover, adopt changes demands in load ,  mitigate disruptions such as misconfiguration

API Gateway for throttling requests
Multiple Direct Connect connections
Automation , health checks and auto scaling

ELB Access Logs 
client IP, latencies

AWS VPC Flow Logs
troubleshoot network connectivity and security logs

Security and Compliance is shared responsibility b/w AWS and Customer

using EC2 instance is IAAS 
AWS only responsible for infrastructure only

4) PERFORMANCE PILAR
Use right solutions Efficiently
Product specific features
S3 Transfer acceleration , EBS optimised instances

5) COST OPTIMIZATION PILAR
Track you expenditure
cost explorer
aws budget 
use tags on resources, helps in measure ROI

Right Sizing
** Trusted advisor for recommendations

Well Architected Tool
AWS service used to lean,measure and build using architectural best practices

AWS TRUSTED ADVISOR
**  High level AWS account assessment

All AWS customers get 4 checks free
1)* Service Limits (identify if service usage > 80% of service limits)
2) SG having unrestricted access
3) Proper use of IAM
4) MFA on Root Account


AWS SERVICE QUOTAS
AWS account has regional-specific default quotas or limits for each service
A Service Quotas allows you to manage your quotas /limits for over 100 AWS services from one location



------------- -AWS KMS -----------------------------------------------------------
Key Management Service (a multi tenant service) 
* AWS manage keys for us
Able to audit key usage using cloudTrail
* Integrate with all aws services that need data encryption
Automatically rotate master key once in a year
* Schedule key deletion
* mandatory min wait period 7 days (max 30 days) 
* Can't directly delete the key (either disable it or schedule key for deletion)
*  Its a managed service 
*  pay for API call to KMS ($0.03 / 10000 calls)
* KMS can only help in encrypting up to 4KB of data per call
* if data > 4 KB, use Envelope Encryption

to give access to KMS to someone
Mare sure the key policy allows the user and Mare sure the IAM policy allows the API calls

** KMS keys are regional specific  (can' t use same key in other region)
1) create snapshot encrypted with KeyA
2) copy snapshot to other region and encrypt with Key2
3) create EBS volume encrypted with Key2

Default KMS key policy
create automatically if not provided and  complete access to root user

Custom KMS key policy
define users, roles that can access and  KMS key


Customer master keys CMK are the primary resources in AWS KMS.
A customer master key (CMK) is a logical representation of a master key. The CMK includes metadata, such as the key ID, creation date, description, and key state. The CMK also contains the key material used to encrypt and decrypt data.

1) Customer managed CMKs are CMKs in your AWS account that you create, own, and manage. You have full control over these CMKs,
Every 365 days (1 year).
used only for my account 
 Only You can control the entire lifecycle of the key, grant permissions, delete and track who uses the key and for what purpose
1$ per month until deletion


2) AWS managed CMKs are CMKs in your account that are created, managed, and used on your behalf by an AWS service that is integrated with AWS KM
You can view their metadata , However, you cannot manage these CMKs, rotate them, or change their key policies
used only for my account 
These type of CMKs are created and managed on your behalf by an AWS service which is integrated with the KMS. If you are trying to encrypt a resource on an AWS Service for the first time and you do not specify a CMK to be used, then that particular service will create an AWS managed CMK on your behalf to get the job done.
You can only view it, you cannot do modifications. You cannot delete an AWS managed CMK

free until in free tier

3) AWS owned CMKs are a collection of CMKs that an AWS service owns and manages for use in multiple AWS accounts. Although AWS owned CMKs are not in your AWS account, an AWS service can use its AWS owned CMKs to protect the resources in your account.
 is completely owned and managed by AWS for use in multiple AWS accounts.
 You have no control over them. You cannot view, manage or use AWS owned CMKs or audit their use
You will not be charged any monthly fees or usage fees for the AWS Owned CMKs.They do not count against KMS





CMK never leaves  KMS
*  Encryption of data key - KMS using CMK
*  Encryption of Data - S3 using data key

You can associate a key/ map called encryption context with any cryptographic operation
if encryption key context is different , decryption failed


1) Symmetric Key Encryptions (AES-256 keys)
use same key for encryption/decryption
SKE is Must for envelope encryption


2) Asymmetric Key Encryption (Public key cryptography)
* public key
* private key
* Encrypt data with public key and decrypt using private key

: encrypAWS service needs IAM permissions to use the CMKtion outside of AWS by users who can't call private key 

------------* AWS Systems Manager Parameter Store --------------------
 SSM Parameter Store which is a secured and managed key/value store perfect for storing parameters, secrets, and configuration information.
* provides secure, hierarchical storage for configuration 
* Parameter Store is an AWS service that stores strings

-------------------------AWS Secrets Manager- (Latest)-----------------------
*  To store secrets (new service)
** Capability to force rotation of secrets every x days
*** Integration with RDS (MySQL, PostgresSQL, Aurora)
ecrets are encrypted using KMS


-----------AWS CloudHSM----------
** you manage your own encryption keys 
** HSM is a tamper resistant FIPS 140-2 level 3 compliance 
** use two or more HSMs in separate AZ in production clusters (must setup)
** supports both symmetric and asymmetric encryption
*  No free tier available
**  must use CloudHSM client software
** Good option to use with SSE-C encryption
** AWS can't recover your keys if you loose your credentials
TDE for oracle db
if You want a dedicated hardware security module with cloud

S3 Encryption 

1) SSE-S3
S3 manages its own keys
keys rotated every month
request header

2) SSE-KMS
Customer managed keys in KMS

3) SSE-C
customer sends the key in every request 
S3 performs encryption/decryption without storing the key
Https is must

4) Client Side Encryption
Customer send encryption data to AWS service
Amazon S3 encryption client can be used 

---------AWS Shield--------------

*  shields from distributed denial of service attacks DDoS
eg. sending million request to the server
protect Route S3,CloudFront,Global Accelerator,EC2,ELB

1) AWS Shield Standard 
Free service
*  activated by default

2) AWS Shield Advanced
paid service, $3000 per month per organization
** 24X7 access to AWS DDoS response team DRP
** protect your AWS bills from usage spikes


------AWS WAF  Web Application Firewall-----------


Protect web applications from OWASP to 10 (Open web application security project)
* layer 7 HTTP
*** can be deployed on CloudFront,ALB,API Gateway
web traffic filtering, block attacks
Define Web ACL (Web access control list)
rules can include : IP address, http header , http body or URI string


--------AWS Firewall Manager ------
AWS Firewall Manager to manage firewall rules across organisational accounts
** common set of security rules


Sample Reference Architecture for DDos Protection
Client --> Route 53 (AWS shield) -> CloudFront (AWS shield OR WAF) --> VPC -> ALB(Security Group  AWS Shield) in public subnet -> SG(private subnet)

-------------------------------------------------------------------------------------------------------------------

Max 5  custom VPC in a Region but 1 default VPC
200 subnets in a VPC
200 routing table
Max 5 Elastic IP in an account (may be extend based on request to AWS)

** VPC is created in a Region and not in AZs
** its all properties are regional

** can't use same CIDR in other VPC in the same region
but for VPC peering (communicate) both CIDR should be different

** Subnet is created in AZ and not in region
Once a VPC is created, you can't change its CIDR block range
Neither VPC nor Subnet extends to two diff AZ

If both IPs results in same network IP then it means that these are part of same network

To find network ID
Network bits   = 1
Host bit      = 0

Class A  1 -   126 	NHHHH
Class B  128 - 191	NNHH
Class C  192 - 223	NNNH

*** Subnet mask allows part of underlying IP to get additional next values from the base IP
2^ (32 - n )
/32 allows for 1 IP =  2^(32 - 32) =   2^0 = 1
/16 allows 65536 IP = 2^(32-16) = 65536

/32 = No IP number can change
/24 = last IP number can change

--------------------------------------------------------------------------
** Default VP
The default VPC is a public VPC
Default VPC have internet connectivity and all instances have both private and public IP
Automatically created for customer AWS account the very 1st time EC2 resources are provisioned.

Following will create automatically with a default VPC
1) DHCP
2) Network ACL NACL
3) Public Subnet
4) Internet Gateway
5) Route Table (main)

when we create a custom VPC then below created automatically
1) DHCP
2) NACL
3) Security Group

Only private IPv4 created

1 VPC = 1 CIDR
****Block size must be between /16 and /28
min /28 = 16 IPS
max /16 = 65536

AS VPC is private , only private IP ranges are allowed
There can't be an overlap of a VPC CIDR block with another connected network

** Each VPC is associated with a Region
** each subnet is created in AZ

VPC = us-east-1
Subnets = us-east-1a,us-east-1b
No. of subnets = No. of AZ

***** AWS reserves 5 IPs (first 4 and last 1) in each subnet
 if u need 29 IP for Ec2 instance
you need at least 64 IP, subnet size /26 = ^(32-26) = 64-5 = 59

------------ Internet Gateway --------------------------------------

** IGW helps our VPC instances connect with the internet
**  Must be created separately from VPC
*** 1 VPC <-> 1 IGW 
IGW own their own don't allow internet access, 
Route tables must also be edited

1) Each VPC when created has a main route table by default 
(enable communication b/w resources in all subnets in a VPC)
2) Default route rule can't be deleted/edited
3) Each subnet can have its route table or share its route table with VPC
4) Multiple subnets can share a route table
5) A subnet can be associated with one route table ONLY
 
 1 Subnet <-> 1 Route Table

For any IP accessing from EC2 to outside, go to Internet Gateway
Destination
0.0.0.0/0     

Target 
IGW_ID

IGW supports both IPv4 and IPV6 traffic

IGW serves two purposes
1) Provide a Target in VPC route table for internet traffic
2) Perform Network Address Translation for the instances that have not been assigned public IPV4 addresses

-----------------------------------------------------------
 Default SG is created when we created a VPC
allows all outbound traffic and denied all in bound
** Can be edited but not Deleted
Security Group can have many to many relationship with Resources (in same VPC)

rdp : 8889
PostgreSQL/Aurora :5432
MySQL/Aurora/Maria DB :3306
MSSQL  Server:1433

---------------------------------------------------------------------------
NAT device to enable instances in a private subnet to connect to the internet (for example, for software updates) or other AWS services, but prevent the internet from initiating connections with the instances. 
A NAT device forwards traffic from the instances in the private subnet to the internet or other AWS services, 
and then sends the response back to the instances. 
When traffic goes to the internet, the source IPv4 address is replaced with the NAT device’s address and similarly, when the response traffic goes to those instances, the NAT device translates the address back to 
those instances’ private IPv4 addresses

NAT comes in 2 flavours
1) NAT Instances (outdated)
2) NAT Gateway


-------------------------NAT instances----------------------------------
***Allow instances in the private subnets to connect to the internet
***NAT instance must be launched in a public subnet
*** Must Disable EC2 flag: source/destination check
*** NAT instance Must have Public IP or Elastic IP attached to it

NAT instance uses public route table to connect to internet gateway for internet traffic
Route table must be configured to route traffic from private subnets to NAT instance
EC2 in private subnet connect to private subnet route table which is connected to NAT instance

NAT instance AMI
Amazon provides Amazon Linux AMIs that are configured to run as NAT instances with name "amzn-ami-vpc-nat" 
Amazon Linux AMI pre-configured are available
***No HA/resilient setup out of box
need to create ASG in muti AZ and resilient user-data script
**Need to manage SG and inbound/outbound rules
*** Bandwidth depends on EC2 instance

----------------------VPC Endpoint ----------------------
VPC Endpoints are virtual devices and are horizontally scaled, redundant, and highly available
*** VPC endpoints make it possible to access AWS services like S3, CloudWatch, DynamoDB 
within a private network (private subnet) instead of public www network
Securely connect your VPC to another service

Instances in the VPC do not require public IP addresses to communicate with resources in the service. Traffic between the VPC and the other service does not leave the Amazon network.

** they scale horizontally and are redundant
** they removed the need for IGW,NAT etc to access AWS services

Two Types of VPC endpoints

1) VPC Gateway Endpoint
securely connect to S3 and DynamoDB
endpoint serves as target in your route table for traffic

2) VPC Interface Endpoint (ENI with Private IP)
**securely connect to Aws services other than S3 and DynamoDB
powered by PrivateLink (keep traffic within AWS network)
**need ENI (private IP) as entry point for traffic , 
** must attach security Group

service A in VPC1 can be accessed by App2 in VPC2

** Requires a NLB at Service VPC and ENI Elastic Network Interface in Customer VPC
 If NLB is in multiple AZ and ENI in Multiple AZ, then the solution is Fault Tolerant

------------VPC Flow Logs ---------------
*** Monitor network traffic#

Flow logs can be created for VPC, Subnet OR Network Interface
Query VPC flow logs using S3 Athena or CloudWatch logs insight
Action: success or failure due to SG/NACL

if problem with request -> problem with NACL or SG
if problem with response -> problem with NACL

-------AWS and On-Premises ---------------------

1) -------Virtual Private Network (VPN)------- ----------------------------------
called AWS managed VP (Site to Site VPN)

AWS managed VPN consists of two parts

    Virtual Private Gateway (VPG) on AWS side
    Customer Gateway (CGW) on the on-premises data center

***IPsec VPN tunnels from VPC to Customer Network over internet
Encrypted using IPsec protocol
low cost, quick to setup but not reliable because of internet

Virtual Private Gateway are Highly Available as it represents two distinct VPN endpoints, physically located in separate data centers to increase the availability of the VPN connection.


Virtual Private Gateway to connect one VPC to customer Network
Customer Gateway installed in customer network and u need a internet routable IP address of customer gateway
Use static internet -routable IP address for your Customer Gateway Device
if behind a CGW behind NAT , use public IP address of NAT 



-2)--------------------AWS Direct Connect (DC) --------------------------------------------

Private Dedicated Network, Physical link
*** Direct Connection must be setup between your DC and AWS Direct Connect Locations
**** You need to setup a Virtual Private Gateway on your VPC
Access public resources (S3) and private (EC2) on the same connection

Private Connection
Customer network -> AWS Direct Connect location (customer/partner router) > 
(AWS Direct Connect endpoint) -> VPC (Virtual private Gateway) 

Public Connection
Customer network -> AWS Direct Connect location (customer/partner router) > 
(AWS Direct Connect endpoint) -> S3

Supports both IPV4 and IPv6
can reduce ISP  bandwidth costs

* Establish DC can takes more than a month
* Establish redundant DC for max reliability
*** DC doesn't encrypt data in transit , (private connection only)


Direct Connect Connection Types

1)  Dedicated  Connections
1 GBPS and 10 GBPS
physical Ethernet port dedicated to a customer
request made to AWS first then completed by AWS Direct Connect Partners

2) Hosted Connections: 
shared 50 MBPS to 10 GBPS
Connection requests are made via AWS Direct Connect Partner

--------Direct Connect Encryption--(AWS Direct Connect  + VPN)---------------------------------

IPsec site-to-site VPN tunnel from an direct connect location to customer network
Traffic is encrypted using IPsec protocol

Customer DC -> VPN - Direct Connect Location


---------------Direct Connect Gateway----(Multiple VPC in diff Regions)-----------------------------------
** if you want to setup a direct connect from on-premise DC to one or more VPC
in different regions(same account), you must use  Direct Connect Gateway


 NAT Gateway (latest)
* AWS managed NAT, higher bandwidth , better availability , no admin
** NAT is created in a specific AZ uses Elastic IP, It is resilient within a single AZ
** Must create multiple NAT Gateway in multiple AZ for fault-tolerance
You cannot associate a security group with a NAT gateway.
can't be used by an instance in that subnet (only from other subnets)
** Requires Internet Gateway (Private subnet -> NAT GW -> IGW)
5 Gbps with auto scaling up to 45Gbps

pay by the hour for usage and bandwidth

Deleting a NAT gateway disassociates its Elastic IP address, but does not release the address from your account.
You cannot route traffic to a NAT gateway through a VPC peering connection, a Site-to-Site VPN connection, or AWS Direct Connect
A NAT gateway supports the following protocols: TCP, UDP, and ICMP.

------------------Egress Only Internet Gateway--------------------------------
NAT gateways are not supported for IPv6 traffic, use an outbound-only (egress-only) internet gateway instead. 
Egress-only Internet gateway is a horizontally scaled, redundant, and highly available VPC component that allows outbound communication over IPv6 from instances in the VPC to the Internet, and prevents the Internet from initiating an IPv6 connection with your instances.
All IPv6 are public addresses
therefore all our instances with IPv6 are publicly accessible
**Egress only internet Gateway gives our IPv6 instance access to the internet

------DNS Resolution in VPC----

** If you use custom DNS domain names in a private zone in Route53, you must set both 
these attributes to true

1) ** enableDnsSupport (DNS resolution setting) DNS resolution is supported for VPC
by default = true
if true, queries the AWS DNS server at 169.254.169.253

2) ** enableDnsHostname (DNS Hostname setting)
by default = false for newly created VPC
by default  = true for Default VPC
if true , assign public hostname to EC2 instance if it has public

---------- NACL ---------------------------------------------------------
NACL is a stateless firewall at subnet level
** for NACL (stateless) both inbound and outbound rules always evaluated
** for SG (stateful) if inbound is allowed , no outbound evaluated
** NACL are like a firewall which control traffic from and to subnet
**Default NACL allows all inbound and outbound traffic
custom created NACL denies all inbound and outbound traffic by default
rules have priory no. (lower has high value)  (1- 32766) 
 1 Subnet associate with 1 NACL
Automatically applies to all instances in the subnets its associated with
** allow rules and deny rules
 NACL are great way of blocking specific IP at the subnet level
Ephemeral Port must be opened

SG  works at instance level#
** only allow rules
** All rules evaluated in SG
traffic allowed if there is matching rule

Can we allow External access to your resources in a VPC
Yes (using Internet Gateway)

subnet should be in AZ belonging to the VPC's region

When you create a subnet, you specify the CIDR block for the subnet, which is a subset of the VPC CIDR block

----------------------VPC Peering-------
VPC peering connection enables networking connection between two VPCs to route traffic between them using private IPv4 addresses or IPv6 addresses
between your own VPCs, or with a VPC in another AWS account

Inter-region VPC peering connection
VPC peering connections can be created across regions

VPC peering uses existing underlying AWS infrastructure; it is neither a gateway nor a VPN connection,
Must update route tables in each VPC's subnets to ensure instances can communicate
VPC  peering can work cross -account

Cannot be used with Overlapping CIDR blocks (CIDR block of each VPC is complete different)
Doe not support Edge to Edge routing through Gateway or private connection
Does not provide Transitive peering  A-B-C so not A-C

-----------------------------AWS VPN CloudHub-------------------------------------------
when u need network connectivity b/w your multiple branch offices (data centres)
* LOW COST  HUB -AND-SPOKE model for primary or secondary network connectivity b/w locations
CloudHub can be connect on Direct Connect or via VPN
install Virtual Private Gateway at AWS and Customer Gateways in customer offices
** Its a VPN connection so it goes over Internet

Customer DC 1 and  Customer DC 2 connect to AWS CloudHub via VPN over internet
and thus they can access each other

AWS VPN CloudHub leverages VPC virtual private gateway with multiple gateways, each using unique BGP autonomous system numbers (ASNs).



--------------Transit Gateway --STAR connection---(Prefer)------------------------------------------------

** Transit gateway enables you to attach VPCs (across accounts) 
and VPN connections in the same Region and route traffic between them
** Supports IP multicast (not supported by any other aws service)\

Transit gateways support dynamic and static routing between attached VPCs and VPN connections

Transitive peering b/w thousands of VPC and on-premise , hub -and-spoke  
It simplify network topology

share cross account using RAM
route tables: limit which VPC can talk with other VPC
works with DC GW and VPN connections

Transit gateway removes the need for using full mesh VPC Peering and Transit VPC
Transit Gateway improves bandwidth for inter-VPC communication to burst speeds of 50 Gbps per AZ.
Transit Gateway abstracts away the complexity of maintaining VPN connections with hundreds of VPCs

--------------Transit VPC -------------------------------------
A transit VPC is a common strategy for connecting multiple, geographically disperse VPCs and remote networks in order to create a global network transit center.

A transit VPC is a common strategy for connecting multiple, geographically disperse VPCs and remote networks in order to create a global network transit center.
A transit VPC simplifies network management and minimizes the number of connections required to connect multiple VPCs and remote networks
Transit VPC can be used to support important use cases 

Private Networking – You can build a private network that spans two or more AWS Regions.
Shared Connectivity – Multiple VPCs can share connections to data centers, partner networks, and other clouds.
Cross-Account AWS Usage – The VPCs and the AWS resources within them can reside in multiple AWS accounts.


--------------------Software VPN---------------------------------
Fully managed both sides of AWS VPC connectivity
Run software VPN appliance in your VPC
recommanded for Compliance as you need to manage both sides of the connection
Recommended when u use gateway devices which are not supported by AWS VPN
u responsible e for patches and updates
and its become a single point of failure

-------------------------------------------------------------------------------------------------------------


---------Route 53 -----------
* It is a Global Service 

Route53 = Domain Registrar + DNS
ie 

Hosted Zone
Is a container for records containing DNS records routing traffic for a specific domain

Route53 can do
Load Balancing (through DNS called client load balancing)
health checks can be linked to Route53 DNS queries
Routing Policies (simple, failover,...)

Not for free tier
you pay 0.05 $ per month per hosted zone

Route53 as a Registrar
a domain registrar is an organisation that manages the reservation of internet domain names
eg GoDaddy, google domains


COMMON/ STANDARD DNS RECORDS

Type
A	: hostname to IPV4 address
AAAA	: hostname to IPV6 address

CNAME   : hostname1 to hostname2 mapping 
only be created for non root domains  
Only for Non root domain like yourapp.yourdomain.com


Alias   : hostname to AWS resource
** Alias records can be create for root and non root domains
ie in28minutes.com   or API.in28minutes.com
if you want to route domain to an AWS resource then what u need to make of use Alias records

AWS Route 53 routing policy determines how AWS would respond to the DNS queries and provides multiple Routing policy options

ROUTE 53 POLICIES

1) Simple Routed Policy
maps a domain name to an IP address
use when you redirect to a single resource                 
You can't attach health checks to simple routing policy
if multiple values are returned , a random one is chosen by the client browser called client site load balancing


2) Weighted Routed Policy
Maps a single DNS name to multiple weighted resources, 10% to A, 30% to b (useful for Canary deployments)
helpful to split traffic b/w two Regions
robability of any one resource record set being selected depends on its weight as a proportion of the total weight


3) Latency Routed Policy
** Users location to AWS region with Min Latency
provides u which region gives u low latency 
Latency-based Routing Policy enables Route 53 to respond to the DNS query based on which data center gives the user the lowest network latency
choose option with min latency
used when there are multiple resources performing the same function 
Latency resource record set can be created for the EC2 resource in each region that hosts the application. When Route 53 receives a query for the corresponding domain, it selects the latency resource record set for the EC2 region that gives the user the lowest latency


4) Failover Routed Policy
active passive failover , ie use DR is primary health check fails
If health check primary fails then requested will be routed to secondary only
health check is mandatory
Failover routing policy is applicable for Public hosted zones only

5) Geolocation Routed Policy
choose based on user location
ie from Pakistan should go to this IP
** should create create a "default" policy in case there is no match
restrict distribution of content to only the locations in which you have distribution rights.
Geolocation routing policy allows geographic locations to be specified by continent, country, or by state 

7) Geoproximity Routed Policy
choose nearest resource (geographic distance) to ur user
Routing policies will route to the nearest resource by geographic distance to your user?
**record set for smallest geographic region has priority

**record set for smallest geographic region has priority

--------------------------------------------------------------------------------------------------------------------
----S3 Fundamentals--
Simple Storage Service
3 is an Object level storage (not a Block level storage) and cannot be used to host OS or dynamic websites
 store large objects with key value approach

100 buckets (soft limit) and maximum of 1000 buckets can be created in each of AWS account

*** bucket name should be using  across AWS accounts (unique)
no space and special or upper case char in Name and become part of object URL ,IP
* must start with lower case letter or number

* S3 is a global service  however a bucket is created in a region
objects are replicated in a single region across  multiple AZ

*** max  size of an object in  a bucket is 5 TB
*** must use multi part upload for uploading more than 5GB

key is full path
keys is composed of Prefix + Object Name
s3://my-bucket/myFolder1/fileName1.txt


PATH
s3://bucketName/key
s3://my-s3-bucket-1/2030/10/course2.jpg

Versioning is at Bucket level must be enabled first
 any file that is not versioned prior to enable versioning will have version "null"
But if we delete a specific versioned then it will delete permanently
We can't turn off the versioning once set

S3 website endpoints do not support HTTPS.

Server-side encryption encrypts only the object data. Any object metadata is not encrypted.

Four methods for encrypting objects in S3

1)  SSE-S3 (S3-Managed Keys)

S3 encrypts object using its own managed data key and put  the encrypted object in the bucket
SSE-S3 encrypts the Data key with a master key that is regularly rotated.
AES-256 encryption type
*** Must set header:  "x-amz-server-side -encryption":"AES256"

2) SSE-KMS (key management service)

** Must set header:  "x-amz-server-side -encryption":"aws:kms"
KMS uses customer master keys (CMKs) to encrypt the S3 objects.
** With SSE-KMS you let AWS manage the encryption keys but you have full control of the key rotation policy

3) SSE-C
manage your own encryption keys
using data keys fully managed by customer outside of AWS
S3 doesn't store that encryption key
** Https is mandatory
encryption key must be provided in the header for each request
Here you have full control over the encryption keys, and let AWS do the encryption
   

4) Client Side Encryption
encrypt the data before uploading to S3
client libraries like S3 Encryption client can be used
customer fully manages the keys and encryption cycle

Encryption in transit/flight is SSL/TLS
S3 provides both http/https  but https is recommend

Bucket owner is the AWS account that created a bucket
Object owner is the AWS account that uploads the object to a bucket

S3 SECURITY

1) User based
IAM policies, which API should be allowed for a specific user from IAM
User based policies use IAM with S3 to control the type of access a user or group of users has to specific parts of an S3 bucket the AWS account owns
User based policy is always attached to an User, Group or a Role,

2) Resource Based- 
Bucket policies and Access control lists (ACLs) are resource-based because they are attached to the  S3 resources

------Bucket policy ---
Bucket wide rules from S3 console To allow cross account
Bucket policy can be used to grant cross-account access to other AWS accounts or IAM users in other accounts for the bucket and objects in it.

If the Bucket and Object is owned by the same AWS account, Bucket policy can be used to manage the permissions

JSON based , Resources: buckets and objects
Action: set of API to allow or deny
Effect : Allow / Deny
eg.
Grant public access to the bucket
Force objects to be encrypted at upload
grant access to another account (Cross account
Only the bucket owner is allowed to associate a policy with a bucket

Access Control Lists (ACLs)
Each bucket and object has an ACL associated with it.
ACLs are used to grant basic read/write permissions on resources to other AWS accounts.

Bucket ACL
Only way you can grant necessary permissions to the Log Delivery group is via a bucket ACL

Object ACL 
is the only way to manage permission to an object in the bucket not owned by the bucket owner 
When bucket owner is diff from object owner

** Bucket ACL / Object ACL don't have conditions but Bucket polices can have Conditions

An IAM principal can access S3 object if 
the user IAM permission allow it 
OR
The resource policy Allows 
AND 
there's no explicit DENY

Explicit DENY in an IAM policy will take precedence over a bucket policy permission


----------------MFA Delete---------------
* Only the bucket owner (root account) can enable/disable MFA delete
* MFA-Delete currently can only be enabled using CLI

You will need MFA to restrict
* permanently delete an object version
* suspend versioning on the bucket
To use MFA delete, enable versioning on S3



** Pre-singed URLS for a limited time
Also Block public access to the bucket at the account level 

Object Lock  (same as Glacier Vault lock) with versioing 
prevents object from being deleted for a specified amount of time 
** Enable only at the time of creation bucket in advance setting, and with versioning Must enabled

All files in S3 are encrypted by default

S3 Access Logs
It logs all the requests made to buckets, 
and Athena can then be used to run serverless analytics on top of the logs files
* Don't set your logging bucket to be the monitoring bucket, (infinite logging loop)

S3 LifeCycle Rules
Automate the transition of S3 objects between their different tiers


S3 Transfer Acceleration
Amazon S3 Transfer Acceleration enables fast, easy, and secure transfers of files over long distances between your client and an S3 bucket. 

To improve speed of data transfer 
** not free

Events Destination
SNS Topic , SQS queue and Lambda Functions


Versioning CANNOT be configured at an individual object level?

S3 Prefix
search for keys starting with a certain prefix
Used in IAM and Bucket polices to restrict access to a specific files or group of files

CORS
its a web browser based mechanism to allow request to other origins while visiting  main origin

Different origin
http://example.com
http://otherexample.com

*** The request won't fulfilled unless the other origin allows for the request using
** CORS headers (ex:Access-Control-Allow)


Block Public Access is at Higher level than Object ACL (B + O) and Bucket Policy (B)

S3 Default encryption vs Bucket Policies

---------------------------------------------------
S3 Default encryption vs Bucket Policies (old way )

New way is to use "Default encryption" option in S3
** ** Bucket Policies are evaluated before "default encryption"

-------------------------S3 Storage Classes-----------------------

For durability All S3 classes are 11 9s, same durability
All S3 storage classes support SSL encryption of data in transit and data encryption at rest
Encryption is only Mandatory for Galcier and Glaicer Deep archieve
S3 One Zone-1A is not multi AZ (only 1 AZs)

High Availability
S3 Standard (High HA) 99.99% a
S3 One Zone 1A (Lowest HA) 99.5%
Rest all have 99.9% HA

1) Standard S3 - General Purpose (Default)
* Frequently access data
  Data replicated in at least 3 AZs
  per GB cost = 0.025
use cases: 
best performance and frequently accessed
Big data analytics,mobile and gaming , content sharing


2) S3 Standard-1A
 long lived, infrequently access data  (eg backups for DR)
 Data replicated in at least 3 AZs
Objects are available for real-time access.
per GB cost = 0.018
lower than S3 standard
use cases: 
data store for DR and backups
** Minimum storage duration is 30 days
 greater availability and resiliency than the One Zone-1A
 99.9%

3) S3 One Zone-1A
 Non Critical data
  long lived, infrequently access data  (data that can be easily generated again)
*** but available for millisecond
Objects are available for real-time access.
* Data replicated in only 1 AZs (Data is not resilient ) , Hense Less exensive than 1A
per GB cost = 0.0144
use cases:
storing secondary backup copies of on-premise data or storing data that you can easily re create
eg. thumb nails from image 

4) S3- Intelligent-Tiering
same low latency and high throughput performance as of S3 standard
small monthly  monitoring and auto Tiering fee
** automatically moves objects b/w two access tiers based on changing access patterns
Long lived data with changing or unknown access 
99.9% availability 
One tier for frequent access
One tier for low cost access infrequent

Multiple zone for resiliency
AWS choose storage classes standard or standard1A
** Minimum storage duration is 30 days

5) Amazon Glacier
** v. low cost
** 10s of years
** alternative to on-premise magnetic tape
Each item in Glacier is called "Archive" file up to 40TB
Archives are stored in "Vaults"
Archive data with retrieval times ranging from minutes to hour
**  Encryption = Mandatory
0.005
99.9% 

** 3 retrieval options
1) Expedited (1 to 5 mins)
2) Standard (3 to 5 hours)
3) Bulk (5 to 12 hours)
** Minimum storage duration is 90 days

6) Glacier Deep Archive
lowest cost data
Archive data with that  rarely retrieval times ranging from hours  to Days
** Encryption = Mandatory
0.002


1) Standard (12 hours)
2) Bulk (48 hours)
** Minimum storage duration is 180 days
99.9%

**  Life Cycle Rules is NOT FREE
** S3 Cross-Region Replication is NOT FREE
* ReplicationCan  be in same region and multiple region also can be cross account
* Versioning must be enabled for replication


* after activating S3 replication, only new objects replicated
* If you delete with/without version id , delete marker will NOT replicated
* No Channing ie B1-B2-B3 then not B1 to B2 automatically

** S3 CONSISTENCY MODEL
1) READ AFTER WRITE FOR PUTS of new object
means when u create a new objects, it is immediately available

2) EVENTUAL CONSITENCY for Overwrite DELETES and PUTS
means no guarantee, you might get a previous version of data immediately after an object is updated

** There is no way to request or API "strong consistency"


-------S3 Pre signed URL----------
Grant time limited permission (few hours to 7 days) to download objects default= 1 hour
users given a presiged URL inherits the permissions of the person who generated the URL

S3 Access Points
Access points can simplify things interms of porvisioing access to different users
Each user can have a dedicated access point on a bucket and each of these access point has its
own policy
useful when u have a large dataset on a bucket that are accesssed by different users or  applcations
Access point Can also restrict a particular VPC 
*** for App1 we can set different kind of action and for App2 diff action on the same bucket

Prevent Object from being deleted or overwritten
***  Use S3 Object Lock

Protect against accidental deletion
*** Use  Versioning

Avoid Content Scraping
Pre-Signed URL also called Query String Authentication

Enable Cross Domain request to S3 hosted web site
*** Use CORS

Remove objects from bucket after a specified time period
*** use life cycle rules and configure expiration policy

Move data automatically b/w Storage classes
use lifecycle rules

S3 is serverless
S3 automatically scales to high request rates, latency 100-200 ms
Use S3 prefix for perfromance

use multipart upload API
Recommend for files > 100MB and Must for files > 5GB

Get some part of the object
***  Use Byte-Range_fetches

Create inventory of S3 objects 
***  use S3 inventory report

change object metadata or tags or ACL or invoke lambda functions for billions of objects in S3
Generate S3 inventory report and Perform S3 Batch operations using it

Enable S3 Server Access Logs for bucket/object access log and 

S3 Transfer accelerator used fast/secure trasfer only for upload

If you want to ensure that an event notification is sent for every successful write, you can enable versioning on your bucket

S3 Glacier is a separate Regional Service 

S3
WORM write once read many times = Enable object lock policy

S3 Glacier 
WORM write once read many times = Enable Vault lock policyAsynchronous 2 steps 

------------------------------------------------------------------------------------------------------------------

------------------------AWS Athena ------------------------
Serverless service to perform analytics directly against S3 files
** Query Engine over S3
***  uses SQL language 
** Used to analyse data on S3 with out loading into any DB and directly from S3
** charged per query and of data scanned
support scv,json,avro and parquet
pay per query 

** EBS is cheaper than EFS

-----Elastic Beanstalk --------------------------------------------
Managed Service
supports Java,.NET,NODE.JS,PHP,PYTHON,GO ,Rubby and docker apps
You can retain FULL control over ASWS resources created
*** It is ideal for simple web applications
*** Not ideal for Microservice architectures

SQS  + Lambda
***  in case of error msg goes to DLQ set by SQS

SNS + lambda
*** in case of error msg goes to DLQ set by Lambda

-------------High Performance Computing- HPC-----------

1) Data Management and Transfer

AWS Direct Connect
Snowball and snow mobile
AWS DataSync
Move large amount of data between on-premise and S3, EFS,FSx for windows

2) Compute and Networking
Spot instances/
EC2 Placement Groups 10GB/s

higher bandwidth, highest PPP
 ENA Elastic Network Adapter  100GBps
Elastic Fabric Adapter (EFA) only for Linux

3) Storage
EBS: scale up to 64000 IOPS with io provisioned IOPS
Instance Storage : scale too millions of IOPS, linked to EC2

Network Storage
FSx for lustre , millions of IOPS backed by S3
EFSL scale

4) Automation and Orchestration
AWS Batch
supports multi-node parallel jobs which enables run single jobs that span multiple EC2 instances
easily schedule jobs

AWS parallel Cluster
open source cluster management tool to deploy HPC on AWS


High Availability for a Bastion Host
**We can use a Bastion host to ssh into our private instances


IAAS   EC2 to deploy
PAAS   Elastic Beanstalk
CAAS   ECS
FAAS   AWS Fargate

Each zone has at least two AZs
AZ consists of data centres

Region
ap-south-1

Availability Zone (ends regions with a alphabet)
ap-south-1a,  ap-south-1b, ap-south-1c

Control Plane:  Access to aws instances operations via aws API 
Data Plane :    Allow access to aws compute instances

----------AWS Federation-----------------------------------

1) SAML 2.0 Federation (old way) (not recommended by aws)
 To integrate Active Directory or ADFS (any SAML 2.0)
No need to create IAM user 

** New way is to use Amazon Single Sign-on Federation

2) Custom Identity Broker Application
** if your Identity provider is not compatible with SAML 
** it uses STS API, AssumeRole or GetFederationToken

3) Web Identity Federation AssumeRoleWithWebIdentity (not recommended by aws)
authenticate users using web identities 
eg open id (Facebook,google)

4) Amazon Cognito 
Provide direct access to AWS resources from client side (mobile,web ap)
provide temp access to write to S3 using Facebook login with creating IAM users for application user

----AWS Directory Service-----------------
It provide AWS access to on-premise users without IAM users

Option1: AWS Managed  Microsoft AD
Microsoft Active Directory hosted on the AWS
* manage users locally and supports MFA
> 5000 users
Trust relationship needed b/s AWS and on-premise directory

Option2: AD Connector
Directory Gateway (proxy) to redirect  directory requests to on premise AD
 users are managed on the on premise AD
500 -> 5000

Option3: Simple AD
least expensive
< 5000 users , SAMBA4 , can't joined with  on premise AD
** can't joined with  on premise AD
Doesn't support Trust relationship with other AD domains

AWS Support offers four support plans: 
Basic, Developer, Business, and Enterprise.

One IAM user per physical person
One IAM role per application

** A user can belong to multiple groups.
**Groups cannot belong to other groups.
**Groups can be granted permissions using access control policies

You can use the roles to delegate access to users (temporarily security credentials), applications or services that generally do not have access to your AWS resources.
there is a conflict like this, then the DENY PERMISSIONS have the final say

The role is create for what service, select the AWS service and attach policies then attach role

By Default root user access is allowed and IAM user is denied



cross account Access = use role


1) Identity Based policies
 Attached to IAM User, Group or Role
These policies let you specify what that identity can do (its permissions)
All services supported
eg User Can list S3 bucket 


2) Resource Based Policy
** Attached to resource, S3 buckets, SQS, and AWS KMS keys
**Inline Only ,  the policy is an inherent part of the identity.
Focus: Who (which account, it is public), what action ?
Account A can read and modify, Public can read
cross-account access: user access resource directly from is aws account
subset of  services supported


Explicit Allow overrides Implicit (by Defauy) Deny
Explicit Deny overrides everything
By default, all requests are denied. This is called an implicit deny. 
Explicitly deny is most powerful = deny

***** Deny Evaluation -> Organization SCP -> Resource based policies -> IAm permission boundaries -> Identity base policies

 IAM users identities exits until thy are explicitly deleted (no expiration)

** An IAM role can be added to a already running EC2 instance, immediate effective
** An IAM role is not associated with IAM user and not for  long term credentials
when a  resource or an application Assume a Role, it is provided with temporary credentials

AssumeRoleWithSAML
** return credentials for users logged with SAML

AssumeRoleWithWebIdentity
*** return credentials for user logged with IDP (Facebook)
AWS recommend Congnito for this

Amazon STS , Security Token Service
** Allows to grant limited and temporary access to AWS resources
Token is valid up to1 hour (must be refreshed)
**STS is good for cross account access


AWS ORGANIZATIONS (Global service)
Apply Policy based Controls Across Multiple Accounts , Centralized compliance mgmt 
The main account is master account, you can't change it 
Organize accounts into Organizational UnitsOU 

RootOU
	Master Account


**AWS Firewall Manager 
To manage firewall rules Across Organization Accounts
WAF,Shield Advance  protection, security groups

------------------Service Control Policies (SCP)--------------------------

**Service Control policies SCPs to define restrictions across accounts
used to whitelist/black  IAM actions

eg. 
prevent users from disabling AWS config or rules
EC2 is always of specific typ
restrict access to certain services(can't use EMR)
enforce PCI compliance 


**** applied at OU or Account Level 
SCP don't apply to master account

By default, all requests are denied
** Precedence at higher level takes over the lower level element

AWS RESOURCE ACCESS MANAGER (RAM)
share resources with any AWS account or within your AWS Organization
eg.
VPC Subnets (shared networking layer with multiple accounts)
allow to have all resources launched in the same subnet

 Can't share SG and default VPC as selected resource in RAM

AWS Single Sign on (Free)
single account to access multiple websites
** Integration with AWS Organization

IAM Conditions
make IAM policies bit more restricted using Condition element in the JSON
restrict the client IP, region, based on tags

user1 need to access S3 in other account
Option1:   User1 (Account A)   -- Role (Account B)   S3 (Account B)
**** when u assume a role , you give up your original permission and take the permissions assigned to the role

Option2: User1(Account A) --> S3 bucket polices - S3
 *** when using a resource based policy , the principal  doesn't have to give up his permission hence can do both actions in the Account A and Account B

Resource based policy is used by
S3, SNS, SQS

IAM Permission Boundaries
AWS supports permissions boundaries for IAM entities (users or roles). A permissions boundary is an advanced feature in which you use a managed policy to set the maximum permissions that an identity-based policy can grant to an IAM entity. When you set a permissions boundary for an entity, the entity can perform only the actions that are allowed by the policy. 


---------------EC2------------

Billed by seconds


For Enable Ping
ICMP ipv4

t2.micro
t is Instance Family (t is General purpose instance)
2 is Generation 
micro is size (Family Generation Size)

Instance Type: on-demand

nano<micro<small<medium<large<xlarge



*** EC2 uses public key cryptography using RSA
public key is stored in EC2 instance
private key is stored by customer

--------------- Security Group ---------------
Virtul Firewall outside the EC2
specific only ALLOW RULES
No Rule , No Traffic allowed , No EC2 restart

** All inbound traffic is BLOCKED by default

**  You pay for an EC2 instance compute component Only when it is in start state
Allo permissions chmod 0400  to key 

 SG can reference to 
 * IP address
 * CIDR block
 * Security Group
 * But not DNS  name

** All EC2 instances are assigned to private IP address but public is not assigned automatically
** Stop/Start EC2 Public IP is changed but private is same and Elastic IP (if assigned)
** reboot will not change public IP

SG are specific to the Region and to the VPC


------------Elastic IP------------
** Elastic IP is a public IPv4 IP you own as long as u don't delete it
*** You can attach it to one instance at a time
** Max 5 Elastic IP in your account (can request more)
*** Elastic IPs can  be switched to other EC2 instance within the SAME region,they need to be manually detached
*** If elastic ip is not in used or if EC2 instance associated with it is stopped  then u will be charged
better is to release the elastic IP

------------------------------------------

Terminate: EBS volume destroy
EC2 Hibernate available Only for On demand and Reserved instances
** cannot be hibernated more than 60 days


-----------------------------------------------------------
Costly   :  EC2 Dedicated , On-Demand
Cheapest :  Spot

--------------EC2 INSTANCE TYPES-----Launch Modes-----------

1) EC2 On Demand (come and stay at hotel room)
pay for what you use
billing per second, after first minute
** Highest cost but no upfront payment
** recommended for shot term and un interrupted 
** ideal for spiky traffic 
** batch program having unpredictable time

2) EC2 Reserved Instances (planing ahead and long time)

3  types of Reserved Instances

a: Standard Reserved Instance
** 1 or 3 years
up to 75% discount

** pay upfront with long term commitment
Instance family , OS or tenancies (shared/dedicated) CAN'T be changed
instance sizes within the same instance family ie t2.micro to t2.small,large
reserve a specific instance type
** recommanded for steady state usage apps (database)

b. Convertible Reserved Instance with  some flexibility
Instance family , OS or tenancies (shared/dedicated) CAN be changed
instance sizes within the same instance family ie t2.micro to t2.small,large
up to 54% discount

c. Scheduled Reserved Instances
** launch within time window 
when you require a fraction of day/week/month
its regional specific 
restriction: available in few instance types C2,R3,C4,M4 in few regions  
5% to 10% Discount
You can also sell reserved on AWS reserved instance marketplace
 if you don't want to use your reservation.

all upfront < partial upfront < No upfront

3) EC2  Spot Instances (bid for empty room )
** Cheapest up to 90% off But not guarantees compared  to on demand
Quote the max 
** ** Most Cost Efficient

Cancelling a spot requests does not terminate instances
**You must cancel a spot request First and then terminate the spot instances
* Not for critical apps, non time-critical workloads
for batch jobs,data analytics which are resilient to failure
new model: quote your max price,based on long term trends
Can a terminated with a 2 min notice
Best practice: Stop or Hibernate instance on receiving interruption notice as for 
terminate a new instance will be allocated

** Completely close a spot request  in the following order for best practice
1) cancel spot request  (only this can't terminate active spot instances)
2) terminate all spot instances

a: Spot Fleet
Request spot instances across multiple instance types(micro,small,large)
to get better change to have a spot instance
*** Spot Fleet = Set of spot instances + (optional) On-demand instances
Spot fleet stops launching instances when reaching capacity or max cost
Spot Fleets allow us to automatically request spot instances with the lowest price
Load balancing workloads Launch instances of the same size, in any Availability Zone. 
Good for running web services

b: Spot Block
Request spot instances for a specific duration (1 to 6 hrs) without interruption
Defined duration workloads Launch instances into a Spot block for 1 to 6 hours

4) EC2 Dedicated Hosts (Book entire building)
*** Most Expensive
** Physical Dedicated EC2 server for your use
Full control on instance placement
** visibility to underlying sockets/physical cores 
Allocated for 3 years
Recommanded for : complicated licencing model , BYOL, strong compliance requirements
Per Host billing
Instance family  can't change

5) EC2 Dedicated Instances
instances running on hardware that is dedicated to you
Per instance billing
** May share hardware with other Instances with same account
No control over instance placement
Instance family  can't change

EC2 instance Families

r (r4,r5,r5a,r5n) Memory Ram  optimized
c (c4,c5,c5n ) Compute optimised High performance
m ( m4,m5,m6 General purpose)
i (i3,de)  storage optimised
g (g3,g4) GPU optimised 
t (t2,t3,t3a) 




Brustable Instances 
workload with spikes, dev env , small db
in case of spike , it can burst but it utilize "burst credits"

Unlimited mode 
(spike beyond CPU credit at additional costs) 
off for t2 but on for t3 by default
It is possible to have "unlimited burst credit balance" 
you pay extra money if you go over your credit balance, but you don't lose in performance

f  (f1) FPGA instances 
massive parallel processing power as geonomic, data analytics

inf (inf1) Machine learning ASIC instances
image,speech,nlp recognition 

--Launch Template ---------------
Use launch templates to automate instance launches
and enforce best practices across your organization

-------Customised AMI------
AMI can be built for Linux or windows
** Faster boot time
**installing your app ahead of time for faster deploy when auto scale
 Hardening an Image 

AMI take space and live in S3 but can't see them in S3 console
** you get charge for S3 space
* By default your AMI are private, can share them
With  user-data at the launch of EC2 instance increases boot up time
AMI Image have root volume also attach non root volumes

*** If you stopped EC2 instances then still EBS volumes (hard disk) will be there and u will be charged
Owner must grant u read permission for storage either EBS snapshot or S3 bucket

You can't copy an encrypted AMI unless keys were shared
You can't copy an AMI with an associated billingProduct code shared with you

AMI is region locked and Same Id can't be used across regions

------------------------Placement Groups-------------------
Use placement groups to influence the placement of a group of interdependent instances

Add instance to placement group = checked

1) Cluster Placement Group
*** Instances on a same RAC (same hardware)
Single AZ
low latency network communication 
** good for High performance computing
Not available for t2 types
***  Pros: Great Network 10Gbps
Cons: Rack fail, all instances failed
Use Case: Big data jobs to complete v fast,Big data Analysis


2) Partition Placement Group
create multiple partitions across Multiple AZ
each partition is located on Separate AWS Racks
partitions are set of RACs
up to 7 partitions  per AZ and 100s of EC2 instance in a partition
A partition failure can affect many EC2 in it but won't affect other partitions

Use Case: Distributed jobs, HDFS, hadoop , kafka, cassandara, Big data jobs to complete v fast

3) Spread Placement Group
High Availability (instance on diff RAC), High resiliency
Each instance is located in a separate rack in diff AZ
*** Critical applications
Cons: 7 instances per AZ per placement group
Use Case: Apps need High Availability
where each instance must be isolated from failure from each other

----------- ENI --(virtual network interface card)----------------------------------------

Elastic Network Interface is logical component in VPC that represents a virtual network interface card
** Primary ENI is by default and can't be detached
*** ENI lives in one subnet and thus in a single AZ (ENI are bound to AZ)

** No. of EC2 instances = No. of ENI
You can create ENI independently and attach them on fly (move them)
on EC2 instances for failover thus new instance gets IP of old instance

Also we can create our own ENI

A single EC2 instance can now be attached to two ENIs, each one on a distinct subnet. 
Also can Detach it and Attach it to other instance as well

You can apply different security groups to each ENI so that traffic port 80 is allowed through the first ENI, and traffic from the private subnet on port 22 is allowed through the second ENI.

----------------------------------------------Good EC2 Scenarios------------------------------------------------------

Q1:  identify all instances belonging to a project, to an environment
SOL: tags

Q2: Change instance type
SOL: stop the instance and then change its type

Q3: don't want an EC2 instance to be automatically  terminated 
** SOL: Change Termination Protection to Enable

** But EC2 Terminal protection is not Effective for termination from
1) Auto Scaling Groups (ASG)
2) Spot Instances
3) OS shutdown


Q4: Update EC2 instance to a new AMI with latest patches
SOL:create/relaunch a new instance with updated AMI

Q5: create EC2 instances based on on-premise VMs
SOL: yes, using import/export , you are responsible for licenses

Q7: Timeout
SOL:inbound rule for security group to check

Q8: Installing a lot of software sing userdata that slowing down instance launch
how to make it faster
SOL:	custom AMI/Golden AMi

Q9: stopped EC2 instance, will I get bill
SOL: No, But incase if u have storage 

--------------------------------------------------------------------
SCALABILITY = Handle greater load

Horizontal Scale 
increase no. of instances
scale out: increase

Vertical Scale 
increase size of instance
t2.micro to t2.large
common to Non distributed databases
scale up/down

High Availability = Multi AZ

Run instances for the same application across multi AZ

Route53(for multiple regions)
 ELB can be public (accessible over internet ) or private to aws network
distribute load for EC2 which can be in Multiple AZ within A region
LB error 503  at capacity or no registered target


1) CLASSIC LOAD BALANCER----Layer 4 (TCP/TLS & UDP) -----------------
Limiation as One CLB per Application
used when  existing application running in the EC2-Classic network.

** To stop accessing EC2 directly without LB
Open SG of EC2 and put Source : My-LB-Security-Group
*** Classic LB doesn't support multiple target groups

2) APPLICATION LOAD BALNCER  (LAYER 7)
supports web sockets HTTP/HTTPS
** scale automatically
** it is a managed service but we are responsible of scaling EC2 instances
** it can also LB with container apps  on same machine /Lambdas /Web app

Load balancing to multiple Http applications across machines (target groups)
**  Routing tables to diff target groups
Based on URL example.com/users to TG1 and  example.com/accounts t TG2
Based on QueryString and Headers
It has port mapping feature to redirect to a dynamic port in ECS
it is great for Microservice and container based applications
** Cross Zone LB is enabled default

1 Target Group = 1 ALB

** One ALB can support multiple Microservice
*** Create a separate target group for each Microservice

Listener Rules
configure multiple listener rules for the same listener
Each Lister have (protocol + port)
Rules are executed in the Same Order they are configured
Default rule executed at the end
Add Rule
if Path /a/*  THEN forward it to TargetGroup-MicroserviceA

Lister Rules possibilities
1) based  on path = test.com/a to target group A`
2) based  on Host = a.abc.com  to target group A`
3) HTTP header and methods (GET/POST)
4) Query String   (/microservice?name=A)  o target group A , (/microservice?name=B)  o target group B
5) Based on IP all request from a range of IP to a TG A, other to TG B

Deleting LB and Target groups

1) Delete ALB
2) ASG Delete (will automatically delete the instances)
3) Delete Target Groups


-------3)--NETWORK LOAD BALANCER---------LAYER 4 UDP-----------------
*** A static / Elastic IP can be assigned with NLB
can load balance EC2, ECS (container- appl, web apps using IP address)
*No support for Lambdas
handles millions of request per seconds
Less latency 100ms  (400 ms for ALB)

* It has one static IP per AZ  and supports assigning Elastic IP
Not included in Free Tier

** There is no Security Groups at the NLB

Attributes that can be changed 
Delete Protection

------------------------------------------------------------------------
*** Cross Zone load balancing
If enabled , each load balancer instance in a AZ will distribute load evenly to all registered instances in all AZs
CLB (Disabled by Default and No charges  for inter AZ data)
ALB (Enabled by Default  and can't disabled it and No charges  for  inter AZ data)
NLB (Disabled by Default and Pay for changers inter AZ data)

* Both ALB and NLB supports sticky sessions

1)  Delete NLB : My-Network-LB
2)  Delete TargetGroup : TargetGroupForNLB
3)  Terminates all instances

Target Group
Target Group (used to group EC2 instances / lambdas/ or set of IP ) for LB to distribute load)

De-registration delay
*** How long should ELB wait before de-registering a target.
This setting ensure that the load balancer gives in-flight requests a chance to complete execution
Default is 300 seconds/ 5 mins up to an hour , also called Connection draining
eg .it will not entertain new request but wait for 300 sec and then de register the ec2 instance

Slow start duration
when a target is ready 
eg. 10 sec after 10 sec it will send request to newly instance

Algorithm
Round robin 1 by 1
Least outstanding request 

Stickiness
enable  (for session mgmt, send all request by a same user to the same instance
implemented using cookie (stickiness enable unless cookie expired)
Stickiness supported by both ALB and CLB
use case: make sure user doesn't lose his session data
-------------------------------
Register Targets
If you register a target in an enabled Availability Zone, the load balancer starts routing requests to the targets as soon as the registration process completes and the target passes the initial health checks.


---------------------------AUTO SCALING GROUPS`------------------------------------------------------------
scale in and scale out automatically to adjust load
ASG can launch On-demand, Spot OR both
** Best practice: use Launch template with ASG
** ALB can adjust and distribute load to healthy instance

AS Can use T2 unlimited burst feature

*** ASG based on CloudWatch Alarms which monitors a  matrix(CPU utilisation)
***ASG use launch Configurations or Launch Templates (newer)
** IAM role attached to ASG will get assigned to EC2 instances
** ASG is free, you pay for underlying resources
**ASG can terminate instances marked as unhealthy by an ALB

To update ASG, must provide a  new launch template

*** Configure group size and scaling policies
Desired Capacity   = 2  (optional , if not the DC= Min)  how many we want , Desired capacity or size is the ideal number of instances in that auto scaling group
Min Capacity 		 = 1
Max Capacity 		 = 3

basic monitoring for ASG is 300 secs from console and is free
detailed monitoring for ASG is 60 secs from console and is not free

Can put EC2 instance manually to stand by (still part of ASG and changed but no traffic will come to it, use for software upgrade)
**ASG doesn't perform Health Check on instances on stand by state

* Cool down period
Helps to ensure that your ASG doesn't launch or terminate additional instances before the previous scaling activity takes effect
A scaling specific cool down period overrides the default cool down period

It is always recommended to create a scale-in event for every scale out event
** Launch Configuration once created can't be edited 

*** Even  if policy indicates, ASG ensure the desired capacity 
**ASG uses Alarms and Policies to determine scaling

MANUAL SCALING

1) maintained current instance levels at all times
min=max=desired == CONSTANT
when always there is constant load expected

2) Scale Manual
change desired capacity as needed
you need complete control over scaling 

3) Scale based on schedule / predictive scaling/cyclic 
programs with regular schedules
Create Schedule Action

4) Dynamic/Automatic Scaling 
On demand Scale for unpredicable load


TYPES OF DYNAMIC SCALING

1) Target Tracking
Modify current capacity based on the target value for a specific metric

Need to keep/maintain CPU utilisation at 70%
Example of AC  
I need temp to be maintained at 20%

Cool down  period
ignore alarms within this time duration and will not create a new ec2 instance

Warm up period
wait for EC2 instance to start for this time


2) Simple Scaling
more complex policy
+5 if CPU utilisation > 80%
-3 if CPU utilisation < 60%

** waits for cool down period before triggering additional actions

3) Step Scaling (adding steps)
+1 if CPU utilisation between 70% and 80%
+3 if CPU utilisation between 80% and 100% 
- 1 if CPU utilisation between 40% and 50% 

Warm up time can be configured for each instance.

** Here cool down period will Not work in Step Scaling Policy

* Because the ASG has been configured to leverage the ALB health checks, unhealthy instances will be terminated
* The metric "requests per minute" is not an AWS metric, hence it needs to be a custom metric
* Network Load Balancers expose a public static IP, whereas an Application or Classic Load Balancer exposes a static DNS (URL)
* SNI (Server Name Indication) is a feature allowing you to expose multiple SSL certs if the client supports it.
* The Default Termination Policy for ASG. It tries to balance across AZ first, and then delete based on the age of the launch configuration. 

---------------- AUTO SCALING SCENARIOS----------------------------

1) change instance type or size of ASG instances
OR 
roll out a new security patch (new AMI) to all ASG instances.
Sol:
*** launch configuration or launch template cannot be edited
create a new version and ASG use that  version
Terminate instances in small groups to make sure application is available

2)  Perform actions before instance added/remove
Create a lifecycle hook , 
configure cloudwatch to trigger actions based on it

3) which instance is terminated first when scale in
based on termination policy
default is distribute instances across AZ then based on old instance

4) Prevent Frequent scale up/down
**Adjust cool down period to a high value (default 300 sec /  5 mins)

5) I want to protect newly launched instance from scale-in (terminate)
Enable instance scaling protection
if enabled then all new instances from this ASG will not be scale in

*** To scale a resource other than EC2, you can use the Application Auto Scaling API, 
which allows you to define scaling policies to automatically scale your AWS resources or schedule one-time or recurring scaling actions.

AWS Auto Scaling is enabled by Amazon CloudWatch, so service fees apply for CloudWatch and your application resources (such as Amazon EC2 instances, Elastic Load Balancing load balancers, etc.).

*** ASG Termination Policy
1) Find AZ which has most no. of instances
2) If there are multiple instances in a AZ, delete the one with oldest configurations


------------------------------------Availability-------------------------------------------------------------

Are applications are available when users need them
Percentage of time
99.99% is four 9s availability

99.95% 	22 mins down time in a month
99.99%   	4.5 mins
99.9995 	26 seconds 

To achieve Availability

1) use LB
2) deploy EC2 instances to multiple AZ's
3) use cross Zone LB
4) Deploy to multiple region
5) configure EC2 and ELB health checks

*** ALB by default enabled Cross Zone LB
CLB and NLB it need to be enabled


----------------Elastic Load Balancer Advance------------------------------------------------------------------

When ELB is detached, it enters the Removing state while deregistering the instances in the group.
Instances remain running after they are deregistered from the ELB

When one AZ becomes unhealthy or unavailable, Auto Scaling launches new instances in an unaffected AZ
Elastic Load balancer can be setup to distribute incoming requests across EC2 instances in a single AZ or multiple AZs within a region

Auto Scaling group can be associated with a load balancer enabled to use the Elastic Load Balancing health check, 
Auto Scaling determines the health status of the instances by checking the results of both EC2 instance status and Elastic Load Balancing instance health.
After registering one or more load balancers with the Auto Scaling group, Auto Scaling group can be configured to use ELB metrics (such as request latency or request count) to scale the application automatically

Auto Scaling marks an instance unhealthy and launches a replacement if

    the instance is in a state other than running,
    the system status is impaired, or
    Elastic Load Balancing reports the instance state as OutOfService.

When the instance is terminated, any associated Elastic IP addresses are disassociated and are not automatically associated with the new instance.
Elastic IP addresses must be associated with the new instance manually.
Similarly, when the instance is terminated, its attached EBS volumes are detached and must be attached to the new instance manually


When this situations occur, Auto Scaling chooses the policy that has the greatest impact i.e. provides the largest capacity for both scale out and scale in on the Auto Scaling group for e.g. 
if two policies are triggered at the same time and Policy 1 instructs to scale out the instance by 1 while Policy 2 instructs to scale out the instances by 2, 
Auto Scaling will use the Policy 2 and scale out the instances by 2 as it has a greater impact

Note that if an instance becomes unhealthy, Auto Scaling does not wait for the cooldown period to complete before replacing the unhealthy instance.

Instance protection controls whether Auto Scaling can terminate a particular instance or not.
Instance protection can be enabled on a Auto Scaling group or an individual instance as well, at any time

When the instance is in the standby state, instance can be updated or used for troubleshooting
If a load balancer is associated with Auto Scaling, the instance is automatically deregistered when the instance is in Standby state and registered again when the instance exits the Standby state

-------------SSL/TLS - basis-------------------------------

SSL Certificate (in-flight encryption)
TLS Transport Layer Security , is new version of SSL
SSL certificates are issued by CA ie Symantec,Comodo

for Https we need to install ssl or tls certificates on the server
in AWS SSL certificates can be managed using AWS Certificate Manager

** ELB requires X.509 certificates (ssl/tsl)

Client -> ELB 		HTTPS
ELB -> EC2          HTTP

Network LB TLS Termination
Client -> NLB  TLS
NLB -> EC2    TCP

-------------Server Name Indication----------------------------------
** Allows multiple SSL certificates onto one web server to sever multiple websites
newer protocol and require client to indicate the hostname of the target server in the initial SSL handshake

Client 
ALB (SSL1, SSL2) based on request will get the appropriate certificate 
ie for each rule we can have different certificate

** SNI Only works for ALB and NLB

Each listener in ALB can be associated with multiple SSL certificates (one for each website)
and SNI ServerName Indication is automatically enabled
its extension to TLS

--Monitoring ELB logs and Headers -------------------------------

ELB --> Action
Edit LB attributes
Access logs 

** NLB allows EC2 instances to see client details like IP but not ALB in request header

X-Forwarded-For      Client IP
X-Forwarded-Proto   Originating protocol
X-Forwarded-Port     Originating port

**** IMP ALB VS NLB VS CLB read again

----------ELB Connection Draining --------------------
*** It is the time to complete "In-Flight Requests " while the instance is de-registering or unhealthy

For CLB it is Connection Draining
For ALB and NLB , Its De-registration Delay at Target Group


-------------IMP LB SCENARIOS --------------------------------------------------------------------------------------

1)maintain sticky session
enable stickiness on ELB (cookie name normally: AWSELB)

2)distribute load only yo healthy instances
configure health

3) configure load among 2 AZ in the same region
Enable cross zone load balancing

4)  in-flight request to unhealthy instances to given opportunity to complete
*** Enable connection draining 

5) warm up time to EC2 instances before getting load
configure health check Grace Period

6) protect EBL from web attacks, sql injection, cross-site-scripting
* integrate ELB with WAF web application Firewall

7) Protect web app from DDoS attacks 
* by default ELB provide it

-----------Architectural Considerations ----------------------------------------

Security
use security groups to restrict traffic
EC2 instances in private VPC (should not accessible out side AWS network)
Use dedicated hosts when u have regulatory needs

Performance
right instance family
appropriate placement groups
prefer custom AMI to install software using user data 
choose right ELB for you use case

Cost
optimal no. and type of EC2 instance family
use right mix of 
saving , reserved , on demand , spot instances

* Resiliency (how quickly u recover)
health checks
cloudwatch for monitoring
DR , ami copied to multiple regions

warm attach = attaching ENI with EC2 instance is stopped

* spot is the cheapest
* on demand is the costly

Monitoring EC2 instances
using 
CloudWatch
basic monitoring every 5 mins Free
CPU,Disk,Network are tracked by cloudwatch

** CW doesn't have access to OS system metric like memory consumption

1) install cloudwatch agent on ec2
2) use cloudwatch collected plug-in
---------------------------------------------------------------------------------------------------------

------------STORAGE----------------

Types of Storage 

1) Block Storage
One or multiple different block storage  device can be connected to one virtual server
Direct Attached Storage: like HD, SAN
High speed network
ie used by DB , oracle and SQL server

2) File Storage
* Shared with multiple virtual servers, Many to Many
user need a  quick way to share files 
Amazon Elastic file server EFS (Linux instances)
Amazon Elastic file server EFx (Windows instances)
Amazon FSx for Luster (High performance use cases)

--------------------------------------------------------------------------------------------

EC2 instances support two types for block level storage 

1) Instance Store
2) EBS

-------------1) Instance stores-----------------------------------------------

*** Physical attached to the host computer where EC2 instances are available
** data lost when hardware/instance fail or instance stop/terminate and not on Reboot
used for temporary data (Ephemeral Storage), cache or scratch files
Only some EC2 instance types supports Instance store, c5 dlarge

Advantages
v fast I/o,  No extra cost  , ideal for storing temporary info

DisAdvantages
** Can't resize the instance store, *** Size is fixed based on instance type
Low boot up up to 5 mins
Cannot take a snapshot or restore
Cannot attach/detach to other EC2 instance


---------------2) Elastic Block Store (EBS)-----------------------------------------------

** Network Storage (not a physical device)
**  Attached to EC2 instance as a network drive
More durable *** EBS volumes preserve their data through instance stops and terminations, 
Provisioned capacity, Highly Flexible increase size when u need
Can be  attach/detach to other EC2 instance
*** 999s availability and replicated within same AZ
**  EBS is Locked to a AZ , to move volume across to other AZ , you first need to snapshot it
*** EBS Volumes in an availability zone CAN ONLY be attached to EC2 instances in the SAME AZ

***UseCase: run your own database
***Require Network to communicate to the instance , means a little latency
*** We billed for provisioned capacity (GBs and IOPS)  and Not for usage
root volume is where OS is stored and it is available by default
multiple volumes can be attached to an EC2 instance


**  A volume to be deleted needs to be first detached But we can't detached a root volume


SSD Solid State Drive
**  Transactional workloads
** recommended for boot volumes

HDD Hard Disk Drive
** Good at  small,random I/O
low cost
Large streaming or big data workloads
Not recommended for boot volumes

-------------------------------------------------------

------------------------------ EBS SSD Types---------------

1) General Purpose SSD (gp2)
** cheap  balance price and performance for transactional workloads
** system boot volumes
** low latency interactive apps

small/medium DB , Dev env
recommended for most workloads

1 GB - 16TB 
burst IOPS to 3000 , Max IOPS 16000

*** IOPS are decrease/increased with value of Size
**  3 IOPS per GB

2) Provisioned IOPS SSD (io1)
** Expensive
** Critical business application
more than 16000 IOPS per volume, max 32000
*** 4GB to 16TB
low latency transactional workloads
Large relational or nosql db
** high performance at high cost

------------------------------ EBS HDD Types---------------

1) Throughput Optimised HDD (st1)
** Frequently accessed,
** Throughput intensive sequential workloads
**  MapRequce,Kafka, log processing , DWH and ETL
500 GB - 16TB , 500 MB/s throughput

2) Cold HDD (sc1)
*** infrequent data access, eg very low transaction databases
lower cost
250 GB - 16TB , 250 MB/s


IOPS Is the standard unit of measurement for the maximum number of reads and writes per second
Throughput is the amount of info you read in each I/O
if you have a big mouth (big throughput), then you will need less bites and less I/O
Use cases:

Work loads -> usually General Purpose Volume
Databases -> usually IOPS (small data but frequently retrieved)
Big Data / Data warehouses -> usually Throughput ( big data files)
Cold HDD -> Cold File Servers (lowest IOPS before moving to Magnetic)

* SSD, Only gp2 and io1 can be used as boot volume

--------------- EBS SNAPSHOT------------------------------------

** backup of EBS volume
Can Cnahge Volume type and size even it is attached with an EC2 instance
Point-in-time snapshots (stored in S3) Aysnc process but Can't accessed directly from S3 but from EC2 API

** Snapshots are incremental
*** We can't loose data if we delete older snapshot
*** snapshot can be shared with other accounts / public
*** max 100,000 snapshots per account
** can make Images AMI from snapshot

EBS Migration
*** EBS Volumes are constrained to  AZs
So to move a volume to another Region, create snapshot of it,copy it to other region,create volume from this copied snapshots in that new region

*** LifeCycle Manager (automated backup solution for EBS volumes) 
Schedule and manage creation and deletion of EBS snapshots

----EBS Encryption-----------

using AWS KMS ** AES-256

Turning on encryption automatically encrypts
Data at rest
data vols, boot vols and snapshots
Data in Transit
b/w EC2 and EBS
b/w EBS and EBS snapshots

Enable encryption at 
*** When EC2 instance is created you can 
*** When copy a snapshot 
** when copy an AMI

When you create an encrypted EBS volume
data at rest is encrypted inside the volume
all data in flight moving b/w instance and vol is encrypted
all snapshots are encrypted
all volumes created from those snapshots are encrypted

Encryption has minimal impact on latency

*** How to encrypt an unencrypted volume
create EBS snapshot of this vol
Encrypt the snapshot using copy (in same region or in order region)
create new EBS vol from this snapshot (which is now encrypted)
attach this encrypted volume to the original instance

Getting faster I/O Performance b/w EC2 and EBS

1) Launch EC2 as "EBS Optimised Instances" during instance creation
2) Enhanced Networking through "ENA Elastic Network Adapter" , increase throughput
3) Using EFA "Elastic Fabric Adapter" , HPC, Only for Linux

EC2 Life Cycle
Hibernate  max 60 days
data in memory is persisted in EBS volume
Only ebs backbend instances can be stopped or hibernated

 ----------EBS Raid Options -------------

RAID
redundant array of independent disks
raid is possible as long as your OS supports it

**RAID 0 (to increase performance)
** Higher IOPS or storage is required
combining 2 or more volumes and getting the total disk space 

use when I/O performance is more important
** Using this we can have a very big disk with lot of IOPS
eg. for a database which has already replication enabled

Dis Adv
When fault tolerance is not reburied
issue is,  data  can be lost if one disk fail

eg two 500 GB EBS io1 vol with 4000 IOPS can create
1000GB RAID 0 with available bandwidth 8000 IOPS and 100 MB/s throughput

RAID 1 (to increase fault tolerance)
when Higher Durability is required
Data is duplicated as data write to both volumes called Mirroring
use case: 
eg two 500 GB EBS io1 vol with 4000 IOPS can create
500GB RAID 1 with available bandwidth 4000 IOPS and 500 MB/s throughput

RAID 5 and RAID 6 is not recommended for EBS

-------- EBS SCENARIO-------------------------------------------------------------------------

1) use an AMI belonging to a different AWS account or in diff region
a) Owner of AMI provides read permission to AMI
b) for encrypted AMI, owner should share encryption keys
c) copy AMI to the other regions

If u don't have permissions to copy AMI but have permission to use it 
Sol:  
create EC2 instance from that AMI 
create new AMI from EC2 instance and copy it 

***  2) Can I attach EBS volume in us-east-1a to EC2 instance in us-east-1b (Diff AZ in same region)
No, it should be in SAME AZ as of EC2 instance

3) Attach multiple EBS volume to an EC2 instance
Yes

*** 4) Attach an EBS volume to two EC2 instances (at the same time)
No

5) Switch EBS vol from EC2 to another EC2
** Yes, detach and attach

6) Will an EBS volume be immediately available when attached to an EC2 instance ?
**Yes, however , by default data is lazily loaded

7) How to endure EBS vol is deleted when EC2 is terminated
Enable delete on termination

8) Retain EBS vol even if EC2 backed instance fail
On termination all data on root is lost even if EBS backed
so detach EBS vol before terminating the instance and recover data by connecting 
it to another EC2 instance
use snapshot

9) How to Create EBS volume from EBS volume in diff AZ in same region
**create snapshot
create EBS volume from that snapshot and select diff AZ

10) How to Create EBS volume from EBS volume in diff Region 
take a snapshot
copy snapshot to other region
create EBS volume in other region

11) Lowest cost option to maintain snapshots with EBS
*** store just latest snapshot and delete others

12) how to encrypt and unencrypted EBS volume
can't do directly
*** create a snapshot from this volume
***create vol from this snapshot with encryption

13) how to automate the complete lifecycle
***** use EBS- Amazon Data LifeCycle Manager
creation, retention and deletion  of EBS snapshots

--------------------------EFS--------------------------------------------------------

ELASTIC FILE SYSTEM

Network File System for Linux instances , POSIX filesystem
*** Can attach a EFS with multiple EC2 (May be in diff Az ) but in a single Region
Petabyte scale , Auto scaling shared file system
Highly available , Highly Scalable more Expensive (3 X gp2), pay per use
** Compatible with Amazon EC2 LINUX based instances only
uses NFS v4.1 protocol
Uses SG to control access to EFS
Encryption at rest using KMS
use "Max I/O Mode" for higher throughput (with small latency) 
use case: home dirs, file share, content mgmt, media workflows

EFS -Performance and Storage Classes

EFS Scale
1000s of concurrent of NFS clients , 10GB/throughput
General  purpose (default) , web server, CMS
Max.I/O higher latency, throughput, high parallel (big data , media processing)

Storage Tiers (lifecycle management feature- move file after n days)

(EFS-IA ) EFS Infrequent Access  
Cost saving , cost to retrieve files , lower price to store

1) Amazon FSx Windows (File Server)
** fully managed windows file system share drive
** SMB service message block and NTFS protocol 
Microsoft AD integration
*** File system data is automatically encrypted at rest and in-transit
*All File sharing options are accessible on AWS or on premises
can be  configured to be Multi AZ (for HA)
Data is backed up daily to S3
build on SSD

*** 2) AMAZON FSx FOR LUSTRE (Linux and cluster)
*** its a File system Optimised for Performance
** HPC high performance computing
machine learning, media processing , Financial modelling
** Seamless Integrates with S3
POSIX complicit
File system data is automatically encrypted at rest and in-transit
can be used from on premise servers


----------------EBS VS EFS ----------------------------------
** EBS is mount to single AZ, attached to one instance at a time
** EFS is mount to multiple AZ
In EBS for auto scaling , you need to provisioned disk and charge for it
In EFS just add files and charged for those files like S3


-----------------------Storage Gateway -------------------------------------------------

AWS Storage Gateway is a Hybrid cloud storage service that gives you on-premises access to virtually unlimited cloud storage

Storage Gateway is the Bridge b/w on-premise and cloud data in S3
Unlimited storage with good performance
VM Image with storage gateway software deployed on-premises

Storage Gateway and S3 glacier encrypt data by default

3 types of Storage Gateway

1) *Storage File Gateway
2) *Storage Tape Gateway
3) *Storage Volume Gateway


1) AWS Storage  File Gateway
** Store Files as object in S3 with a Local Cache
** File share (NFS or SMB)  + It benefits from S3 features and integrations

File Gateway deployed as VM on premises
Bucket access using IAM roles for each File Gateway
Application feels that they are accessing file system locally but it was S3 using FGW

2) AWS Storage Volume Gateway

*** Move Block Storage to cloud
** Block storage using iSCSI protocol backed by S3
Backed by EBS snapshots

** mostly for backup and DR
migration of application data
reduce cost
Backed by EBS snapshots which can help restore on-premise volumes

a) Cached volumes
**  Primary data stored at AWS S3, on premise cache store frequently accessed data

b) Stored Volume
High Performance
** Primary data (entire dataset) store at On premise
async copy to AWS
stored as EBS snapshots
for DR and restore EBS volumes

3) AWS Storage Tape Gateway
used for archives
**backup data using existing tape based processes using iSCI
**VTL Virtual Tape Library backed by S3 and Glacier
** no need to change tape backup infrastructure
backup data to virtual tapes ie S3 and glacier 

scenarios: want to use an AMI belonging to a diff AWS account or a diff Region
** AMI are restricted to a region

File Storage used for HPC High performance computing  is Amazon FSx for Lustre

File gateway- Hardware Appliance
** helpful for daily NFS backups in small data centres

----------------------------------------------- Moving Data b/w AWS and on-premises------------------------------------------------------------------------------

1) S3 transfer Acceleration
*** when transferring less data up to few TB
***basic option
***uses cloudFront edge locations
Enable S3 transfer acceleration and use endpoints

2) AWS Snowball
Transfer dozes of TB to Petabyte from on-premises
***physical shipping
KMS 256 bit encryption
(80 TB usable) per appliance
*** choose snowball if data transfer takes more than a week based on your network connection
data loaded in S3 and snowball is completely wiped

3) Snowball Edge
*** supports custom lambda function*** add Computational capability to the device
compute optimised / storage optimized
use case: pre-process the data while moving

4) AWS Snow Mobile (truck)
petabyte of data
** 100 PB storage per truck
data is automatically encrypted with KMS (AES-256)
1 EB = 1000 PB = 1000,000 TB
use case: when to transfer more than 10 PB

Snowball into Glacier
Not directly
***  First import into S3 and then use S3 lifecycle policy

5) AWS DataSync 
*** Transfer File Storage to cloud
*** Move large amount of data from on-premise to AWS
*** Secure
*** 10 X faster of TB to/from AWS Over internet or AWS Direct Connect
*Transfer from on Premise File storage (NFS,SMB) to S3, EFS,FSx for Windows
* EFS to EFS  in diff regions using DataSync Agent installed in EC2 instances

Integration with AWS storage Gateway for ongoing update
use case: Data Migration,replication and clod data archival

Alternatively, use S3 transfer acceleration if apps integrated with S3 AP1 

-------------------------------------------------------------------------------------------
--------------------------DATABASES--------------------------------------------

**Create snapshot from standby DB so that performance will not impact

99.95% 22 mins in a month
99.99% 4 9's 4 and .5  mins in a month
99.999% 5 9's 26 sec in a month
11 9's durability means store 1 million files for 10 million years, you would expect to lose 1 file

Increase Availability
standbys in Multiple AZ and Multiple Regions

Increase Durability 
Multiple copies of data (standby,transaction logs, replicas) in multiple Az and Regions

very small data loss (RPO 1 min)
very small data loss (RTO 5 min)
Hot Standby (automatically sync data, failover),standby ready

very small data loss (RPO 1 min)
downtime can be tolerate (RTO 15 min)
Warm Standby (automatically sync data,standby with min infra)

Data is critical (RPO 1 min)


Scenario 

Create read replica in multiple regions

Consistency 
data is updated simultaneously in (standbys and replicas)

Strong Consistency
sync replication to all replicas , will be slow if u have multiple replicas/standbys

Eventual Consistency

Amazon RDS 
***  Recommended AWS Service Aurora (based on PostgreSQL)

OLAP
*** analyse petabytes of data
*** Recommended AWS Service  Redshift based on PostgreSQL
*** use columnar storage

Document Databases
*** data stored as set of documents (whole json)
schema-less   semi structure data
adv. horizontal scaleable to TB with ms response million of TPS
***  Recommended AWS Service  DynamoDB

*** Key-value
use simple key-value pair 
key is unique, value can be obj or simple data values
adv. horizontal scaleable to TB with ms response million of TPS
***  Recommended AWS Service  DynamoDB
useCase: shopping cart,gaming apps, v. high traffic web apps

Graph DB
store and navigate data with complex relationships
eg fraud detection , fb, social networking data 
***  Recommended AWS Service  Neptune

In Memory Databases
*** microsecond latency
storing persistent data in memory
Recommended AWS Service
*** Redis  for persistent data
Memcached for simple cache
use cases: session management, geospatial apps

DB Scenarios

***  A start up with quickly evolving tables  ElastiCache
DynamoDB

*** Transaction app need to process millions of TPS
DynamoDB

Very high consistency of data required while  processing thousands of TPS
*** RDS

Cache data from db for a web app
ElastiCache

Relational DB for analytical processing of Petabyte of data
***  RedShift

--------- Amazon RDS--------------------------------------------------------------------------
RDS is a managed service
** Multi AZ deployments (standby in another AZ) for DR
Storage backed by EBS
But you can't ssh in the underlying EC2 of RDS

* Amazon Aurora (postgreSQL + MySQL) not for free tier
PostgresSQL
MYSQL (InnoDB storage engine full support)
MariaDB (enhanced mysql for enterprises)
Oracle DB
Microsoft SQL Server

** Read Replica
Same AZ, Multi AZ, Cross Region
Auto scaling storage

Automated backup

You cannot 
** ssh in db ec2 instance or setup custom software

*  ----------- Multi AZ Deployments ------------------
Mainly used for Disaster Recovery
** Standby created in a diff AZ with one DNS name  for failover
Synchronous replication ** No downtime when DB is converted to MultiAz
apply patches at standby and then switch primary with standby
** standby is automatically deleted when u delete the DB
* Read Replicas can be setup as Multi AZ for DR

* ----------------- Read Replicas ------------------------------
RR used to scale your read
use case: reporting, DWH
** can be in same AZ , diff AZ or diff Region
Can Create read replicas of a read replica
** use Async replication (eventually consistency ie with delay)
** Read Replicas and Manual Snapshots are Not deleted when DB is deleted , needs to delete it manually
** Must to enable automatic backups before creating read replicas

Max No of replicas
* MySQL,mariaDB,PostgresSQL, Oracle = 5
Aws Aurora = 15
SQL Server not supported read replicas

** There is Network Cost when data goes from one AZ to another AZ
DB and Read Replica  if  Within same  AZ  = Free

RDS -Security and Encryption

1) At Rest Encryption
** through IAM and SG
	encrypt master and read replica with AWS KMS - AEC-256 encryption
** Encryption has to be defined at launch time
* If master is not encrypted, the read replica can't be encrypted
Transparent Data Encryption TDE is available for Oracle and SQL server

2) In flight Encryption
SSL certificates to encrypt data to RDS  in flight
To enforce SSL
PostgresSQL : rds.force_ssl=1
MySQL : GRANT USAGE ON *.* TO 'mysqluser'@'%' REQUIRE SSL;

* when Encryption is enabled data in database ,automated backups, read replicas and snapshots are all Encrypted

**  snapshots (backups) of un-encrypted RDS databases are un-encrypted
** snapshots (backups) of encrypted RDS databases are encrypted

To Encrypt an un-encrypted RDS database
create a snapshot of  un-encrypted  db
copy the snapshot and enable encryption for the snapshot
restore the database from encrypted snapshot
migrate application to new db and delete old db

** RDS databases are usually deployed within a private subnet
*** ** IAM policies help control who can manage AWS RDS through RDSAPI ie 
who can create db, delete db

IAM Authentication
** works with MySQL and PostgreSQL only
no need password, just a token obtained through IAM and RDS API calls
valid for 15 mins

RDS Costs

1) DB instance hours
**  2) Storage per GB per month  , you provisioned and not usage


----------------------------------RDS-Amazon Aurora ------------------------------------------

** It is propriety of AWS and not open sourced
AWS cloud optimized and claim 5X performance over MySQL and 3X over Postgres
** Storage automatically grow inclemently of 10GB up to 64GB
** 15 replicas
Instance failover
** Cost is 20% less than RDS but is efficient

** it maintains 6 copies of  your data across 3 AZ
* Read Replicas can be Global 
*** replication + self healing + auto expanding  
it creates cluster of volumes spread across multiple AZ 
***Primary instance  read/write to cluster vol and Replicas read from cluster volume

***provides Global database options (multiple regions)

Aurora Support for Cross Region replication

use case:
same as RDS but with less maintenance / more flexibility / more performance

Deployment Option

3) Aurora Serverless
Automated DB instantiation and auto scaling
***No need to provide the size and capacity planing
* good for infrequent, irregular and unpredictable workloads
*** pay per second and can be more cost effective

GLOBAL  AURORA

1) Cross Region Read replicas
use for DR


***2) Aurora Global Database (recommended)

1  Primary Region (read + write)
up to 5 secondary (read-only ) regions, replication lag < 1 second
up to 6 read replicas per secondary region
*** RTO < 1 min for DR in other region

--------------------------------------------------------------------------------------------------

RDS Scaling
* Normally manual scale up to 64TB 

Autonomic backup during backup windows in S3 , default retain 7 days, max 35 days
***Achieve RPO up to 5 mins

When to use RDS
***1) pre-defined schema
***2) where strong transactional capabilities and complex queries required

RDS is Not  recommend for 
Highly scalable massive read/write eg. millions of writes/sec  (go for DynamoDB)
Upload files using Get/PUT Rest API (use S3)
Heavy customisation for DB or need to access underlying EC2 (Go for custom DB installation)

*** Migrate on-premise database to cloud database of same type
AWS Database Migration Service

Migrate data from one DB engine to other
*** use AWS Schema Conversion tool

reduce Global latency and improve DR
***use multi region read replica

Billed if DB is stopped 
*** Only for storage, IOPS , backups and snapshots
Not billed for DB instance hours

Need RDS for an year, reduce cost 
*** use RDS reserved instances

Efficiently manage DB connections
*** use AWS RDS Proxy
sits b/w client app (including lambda) and RDS

------------------AWS ElasticCache-------------------------------------------

Managed Service
* Highly scalable and low latency in-memory KeyValue data store (* can't use SQL)
*sub millisecond latency
** u can store in memory data in EC

** Must provision an EC2 instance type , NOT serverless

* WRITE scaling using sharding
* READ scaling using Read Replicas

* Multi AZ with failover as a distributed caching solution
*point in time restore feature
 
 *** Don't support IAM authentication
  ElasticCache supports  Redis AUTH
  can you enhance the security of your Redis cache to force users to enter a password?
 can set password/token when u create a redis cluster
  
** Redis and Memcached are two Custer engine for ElasticCache
 
1) Redis (in memory persistence data store)
* Multi AZ deployments with automatic failover
* durability using AOF persistence
*  supports backup (in S3) and restore
* Can be used as database

In case of Failure:
Primary node is replaced, if Multi-AZ replication group is enabled, read replica is promoted to primary

* publish subscribe messaging  (act as a  message broker)
read replicas and failover support
encryption support

2) Memcached (pure caching sol)
** Non persistent cache
distributed , Multi Node for partitioning of data (sharding)
** ideal for front end for data stores like RDS and DynamoDB
can be used as a Transient  session store
create up to 20 cache nodes
Low maintenance simple caching solution
Easy auto scaling
Cluster Engine : Memcached

Limitations
** No backup or  restore supported
** No encryption or replication or snapshot
** when node fails, all data in that node is lost 
reduce impact of failure by using Large no. of small small nodes

Patterns for ElasticCache

1) Lazy Loading
all read data is cached, data can become stale in cache

2) Write Through
add or update data in cache when written to DB (No stale data)

3) Session Store
store temporary session data in cache using TTL feature


------------------------ AWS DynamoDB --------------------------------------------------------

Fully managed , HA, fast, scalable DISTRIBUTED  NoSQL DB for any scale
** schema less ** NoSQL key value and document based
** 3 replica in a single region

Single-digit millisecond latency at any scale.
millions of requests per seconds and trillions of rows , 100s TB of storage
Low cost and auto scaling capability
No need to create  a Database
** Here create a table directly and configure RCU and WCU Read capacity unit
max item size = 400KB
Provides a expensive serverless  mode
** Application which required milli second latency but at v high scale

** Enables event driven programming with DynamoDB streams
Throughput can be extended temporary using "burst credits"
"ProvisionedThroughputException" when burst credits are empty so it is advised to do exponential back-off retry
* can only query on primary key, sort key or indexes
*** Can replace ElasticCache as key/value store for storing session data

** DynamoDB NewFeatures

1) Supports Transactions across multiple tables
include up to 10 unique items or up to 4 MB of data

2) On Demand
**  2.5X more expensive than provisioned capacity
useful in case of un predictable spikes or application is v low throughput

Security 
VPC endpoints available to access DynamoDB without internet
Access controlled by IAM 
Encryption at rest KMS, Encryption in Transit SSL/TSL

Backup and restore
** point in time restore like RDS

Migrate to Dynamo DB using DMS (from MongoDB Oracle,MySWL,S3)

** Global Tables
**  Enable you to use DynamoDB as fully managed , multi region, multi-master database to create global table , 
** Must enabled dynamoDB streams for creating Global tables

Active Active replication , in many regions
useful for DR 
CRUD in one Global table automatically reflected in to other table of different region and vice versa

** connect DynamoDB streams to Lambda functions whenever an item in the table is modified , a new

** partition key is mandatory for search
can't search using only sort key

partition key + sort key = composite pk

DynamoDB Indexes

Local Secondary Index
Same partition key  as of Primary Key but different sort key
Should be created at the table creation

Global Secondary Index
Partition and sort keys are diff from Primary Key
Can be added or removed at any point in time
stored separately from original table

Query VS Scan

Query
search using partition key (PK or Index) and a distinct value to search
Max 1 MB result returned

SCAN
read every item in a table
** expensive 

Consistency Levels
** Eventually consistent (1 sec lag by default)


** **  In DynamoDB, strongly consistent reads are expensive than eventually consistent reads

Provisioned
** Recommended
** provision read and write capacity
** Billed for provisioned capacity  irrespective of whether you used it or not

On Demand
** Truly serverless and expensive
For unknown workloads or traffic with Huge spikes

** Dynamo DB RCU and WRC
Capacity used depends on size of item, read consistency , transnational etc

** On Demand RCU is 8 times the cost of Provisioned RCU

IAM and Encryption
Server side encryption with KMS keys is Always enabled (automatically encrypt tables, streams and backups)

Client Side encryption
DynamoDB Encryption Client

Use IAM roles to provide EC2 instances or AWS services access to DynamoDB tables

DynaymoDB
** milli sec latency with millions TPS but lower Consistency
Difficult to run complex queries
** No upper limit

RDS
** stronger consistency and transactional capabilities
SQL Queries
** Good to run complex queries
** upper Limit 64TB

-----------------** DynamoDB Accelerator (DAX)----------------------------------------------------------------------------

** In memory cache for DynamoDB
microsecond response time

Applications --> DAX -->. DynamoDB

can reduce your costs by saving our read capacity units (lambda reads from DAX rather than hitting DynamoDB)
solves Hot key problem (too many reads)
*** 5 mins TTL
Multi AZ min 3 
Secure , encryption at rest via KMS,VPC,IAM,cloudTrail

Not Recommanded
if u need strongly consistent reads
application is write intensive with very few reads

DynamoDB -> DAX 
create cluster
*** Encryption is recommended

-------------------** DynamoDB Streams--------------------------------------------------------------------------

Changes in DynamoDB (Create,update,delete) can end up in a DynamoDB stream
** each event from DynamoDB  (in a time sequenced order) is buffered  in a stream near real-time
This  stream can be read from AWS lambda 
* could implement cross region replication using streams
* streams has 24 hrs of data retention

EC2 -> DynamoDB -> DynamoDB Streams -> Lambda -> SNS
use case: send email when user registered

--------------------------------------------------------------------------------------------
S3 is a key/value store for objects like a DB
Great for big objects (5 TB) and not for small objects
serverless
--------------------------------------------Neptune----------------------------------------------------------

Fully managed Graph database
High relationship data 
social networking , Wikipedia
HA across 3 AZ with 15 read replica

 ----------------------Redshift----( Relational database)----------------------

Redshift is a petabyte-scale distributed data ware house  
*based on PostgresSQL
*  Redshift is a
*OLAP 
10X better performance than other DW
pay as you go based on instances provisioned
from 1 node to 128 nodes, up to 160GB per node

* Redshift spectrum: perform queries directly against S3 (but not server less like Athena)
* Redshift Enhanced VPC routing, copy/unload goes through VPC and not internet

*1) MPP massive parallel processing
storage and processing b/w multiple nodes
*2) Columnar data storage
*3) High data compression
ie city column

A single row data might be stored across multiple nodes
* A query to redshift leader  node is distributed to multiple compute nodes

** supports standard SQL
* automatic replication (3 copies of data)
* automatic backup (S3 , default retention 1 day, max 35 day)
** Configure Redshift to automatically copy snapshot of a cluster to another Region

Redshift cluster

*Leader node
received sql queries and distributed to compute nodes

* Compute Nodes
can be in multiple AZ
no direct access to leader nodes


* Loading data in Redshift

Simple
SQL insert queries using ODBC and JDBC

Efficient
*  Redshift COPY command to load data from S3,DynamoDB, EMR

On premise data
* user Storage gateway or import/export data into S3 
COPY data from S3

Recommendation
prefer COPY over INSERT for bulk operations as COPY is parallel and INSERT is sequential
prefer COPY from multiple files. split into multiple small input files

Managing Redshift workload (WLM)
used to categorize your queries 
create queues and put  queries in it

Redshift Security

integrates with AWS KMS or AWS Cloud HSM

IAM to manage user permission for cluster operations

** Redshift Spectrum
Run sql queries against datasets in S3 Without loading it
*Query is then submitted to thousands of Redshift Spectrum Nodes
** Must have a Redshift cluster available to start unlike Athena
Avro,parquet, csv,json formats supported

** Eliminate expensive data transfer from S3 to data warehousing solutions (cost effective) 
Integrates with AWS Athena
Query against EMR

--------------------AWS Elasticsearch-----------------------------------------------------------------------------------------------------------

Managed service around Elasticsearch
support ELK stack
Elasticsearch
logstach to inject data
Kibana for dashboard visualization
use case: 
fast search
app/server  monitoring get intelligence from you logs

eg. In DynamoDB we only search by PK or indexes
With ElastiSearch, you can search any field , even partial matches


---IIMP--------------***   RDS for Solution Architect w.rt  well Architected 5 pillars-------------------------------------------------------------------------------

1) Operations
small downtime when failover happ
scaling in read replicas/ec2 instance
DynamoDB:No ops needed, auto scaling and serverless
S3: No operation required
Athena: serverless
Redshift: same as of RDS
Neptune: same as of RDS
ElasticSearch:  same as of RDS

2) Security
OS security by AWS
we will do setting KMS SmG,IAM polices , SSL
ElastiCache: use Redis Auth 
DynamoDB:IAM,KMS,SSL
S3: IAM,Bucket Policy,ACL,Encryption
Athena: IAM + S3 security
Redshift: same as of RDS
Neptune: same as of RDS + IAM
ElasticSearch: Cognito, IAM,VPC,KMS, SSL

3) Reliability
Multi AZ , failover in case of failure
Aurora: Serverless 
ElastiCache: Multi AZ,Clustering
DynamoDB:Multi AZ,Backup
S3: high durability and availability , multi AZ and CRR
Athena: managed service, use Presto engine, High available
Redshift: HA and Auto healing features
Neptune: Multi AZ, Clustering
ElasticSearch: multi AZ, clustering

4) Performance
depends on EC2 instance type, EBS volume type 
ability to Read replica
Doesn't auto scale 
Aurora: 5X faster up to 15 Read Replica
ElastiCache: sub millisecond, in memory, read replicas for sharding
DynamoDB: single digit millisecond, DAX for caching reads
S3: scales to thousands of read/writes, Transfer acceleration , multi part for big files
Athena:query scale based on size
Redshift: 10X faster than other DWH solutions, support Compressions
Neptune: best for graph clustering 
ElasticSearch: open source, petabyte scale

5) Cost
Pay per hour based on EC2 and EBS
\Aurora: pay per hour based on EC2, cost less than enterprise db like Oracle
ElastiCache:  Pay per hour based on EC2 and EBS
DynamoDB: Pay per capacity and storage unit, no need to guess capacity in advance
S3: pay per storage,network cost , no. of requests
Athena:pay per query/per TB data scanned, serverless
Redshift: pay per node provisioned, 1/10 of cost vs other DWS
Neptune: pay per node as RDS
ElasticSearch: pay per node as RDS
















