------------------------------

linked in /stephanemaarek

---------------
Enterprise Integration pattern
knative
quarkus

https://github.com/rh-ei-stp/cloud-native-event-mesh
-------------------

Must To Do
Hybrid Cloud

Career Conversation

update career tool

------------------------------------------------------------

L&K Pakistan
https://w3.ibm.com/w3publisher/l-k-pakistan 

IBM Microsoft  Learning Portal
https://ibm.ontidwit.com/

MEA CTO Office's Personal Room
https://ibm.webex.com/meet/mea.cto.office | 1459398949

Join by video system
Dial mea.cto.office@ibm.webex.com
You can also dial 173.243.2.68 and enter your meeting number.

Join by phone
1-844-531-0958 United States Toll Free
1-669-234-1178 United States Toll
Access code: 145 939 8949

---------------------------------------------------

Application modernization is about building automated, operatable, business focused solutions
you build it , you run it

IBM Cloud Leaning paths
https://ibm.seismic.com/Link/Content/DCoOar42GSrkGLJQWKR050_w
https://www.ibm.com/cloud/architecture/tutorials/power-simplicity-app-connect-integration

ICCT role-based training is free to IBM employees. IBMers should enroll in ICCT courses from Your Learning to avoid charges. 
Click the ICCT on IBM Your Learning link.
https://yourlearning.ibm.com/icct	

Good 
IBM Cloud Architect: Professional
https://yourlearning.ibm.com/activity/PLAN-9DE5A5B18C9D

IBM Cloud Developer: Professional
https://yourlearning.ibm.com/activity/PLAN-785E3A7691DC

Cloud Pak for Integration 
https://community.ibm.com/community/user/imwuc/viewdocument/cloud-native-deployment-automation?CommunityKey=da043955-1299-4c40-a6a8-479e62046c8fhttps://event.on24.com/eventRegistration/console/EventConsoleApollo.jsp?&eventid=2494886&sessionid=1&username=&partnerref=&format=fhvideo1&mobile=&flashsupportedmobiledevice=&helpcenter=&key=B2D186FF6F43A82D60E56C40F819F67D&newConsole=true&nxChe=true&text_language_id=en&playerwidth=748&playerheight=526&eventuserid=340395883&contenttype=A&mediametricsessionid=311153000&mediametricid=3516327&usercd=340395883&mode=launch


Solution architect workshop
https://www.ibm.com/training/course/ZD108G
Exam:
https://www.ibm.com/certify/exam?id=C1000-087
Developer workshop - TBD
Exam:
https://www.ibm.com/certify/exam?id=C1000-099

CP4MCM 1.3 Certification Cohort
https://ibm.ent.box.com/s/hf66mr7kd2l7hyw02l3njmrdr4i6r3iy/folder/120414914422

https://pages.github.ibm.com/ibmdemos-cloudpaks/cloudpak-applications/labs/

VW015

channel name: garage-tsa-appmod-chapter


Microservice for Beginners
Very Good 
https://github.com/ibm/cloud-native-starter
https://developer.ibm.com/videos/teach-your-monolith-to-dance/

https://developer.ibm.com/videos/microservices-for-beginners/?utm_medium=Email&utm_source=Newsletter&utm_content=000039JL&utm_term=10004796&utm_campaign=M00000000&utm_id=Containers2020&cm_mmc=Email_Newsletter-_-Audience+Developer_Developer+Conversation-_-WW_WW-_-Containers2020_ov75905&cm_mmca1=000039JL&cm_mmca2=10004796&spMailingID=43637657&spUserID=Njg0Nzc2NDQzMDIxS0&spJobID=1860650711&spReportId=MTg2MDY1MDcxMQS2

https://github.com/IBM/microservices-using-apiconnect-and-appconnect/blob/master/README.md
----------------------------------------------------------------------------------
AWS Must do 

AWS Exam Readiness
https://www.aws.training/Details/Curriculum?id=20685

AWS Certified Solutions Architect - Associate (SAA-C02): Introduction
https://learning.oreilly.com/videos/aws-certified-solutions/9780136721246/9780136721246-ACS2_00_00_00


White paper and FAQs are must

What is AWS Well-Architected Tool?
https://docs.aws.amazon.com/wellarchitected/latest/userguide/intro.html


cheat sheet
https://tutorialsdojo.com/links-to-all-aws-cheat-sheets/

Find Qualifier  keywords
Elimination Technique
Time Management

cost is tie breaker 
You can enrol for practise tests on the website. https://aws.amazon.com/certification/certified-solutions-architect-associate/
The following links provide more information regarding the topics just discussed. Please review the links in preparation for the exam: Amazon Glacier Documentation: https://docs.aws.amazon.com/glacier/index.html#lang/en_us FAQs: Amazon EFS - https://aws.amazon.com/efs/faq/ Amazon S3 - https://aws.amazon.com/s3/faqs/ Amazon Glacier - https://aws.amazon.com/glacier/faqs/ Amazon CloudFront - https://aws.amazon.com/cloudfront/faqs/ Introduction to Amazon S3 Lab – https://amazon.qwiklabs.com/catalog?keywords=Introduction+to+Amazon+Simple+Storage+Service+%28S3%29&format%5B%5D=any&level%5B%5D=any&duration%5B%5D=any&price%5B%5D=any&modality%5B%5D=any&language%5B%5D=any Introduction to Amazon EFS – https://amazon.qwiklabs.com/catalog?keywords=Introduction+to+Amazon+Elastic+File+System+%28EFS%29&format%5B%5D=any&level%5B%5D=any&duration%5B%5D=any&price%5B%5D=any&modality%5B%5D=any&language%5B%5D=any 

** Must remember the Volume matrix
** AWS Well Architected Framework: 
https://aws.amazon.com/architecture/well-architected/ 


AWS labs
https://amazon.qwiklabs.com/

https://aws.amazon.com/ebs/features/

To Visit for exam readiness
https://pages.awscloud.com/traincert_get_certified_2020.html

https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html for more information on Amazon EC2 instance stores. Amazon EBS FAQs: https://aws.amazon.com/ebs/faqs/ Whitepaper – AWS Storage Services Overview: https://d0.awsstatic.com/whitepapers/Storage/AWS Storage Services Whitepaper-v9.pdf I will share a consolidated towards the end



-----------------------------------------------------------------------------------



------------------------------------------------------------------------
Questions
EC2 Custom AMI vs Custom Template

------------------------------------------------------------------------------------------------------------------------------------------
https://yourlearning.ibm.com/activity/URL-AA49C4823B02

https://smarter-gbs.yourlearning.ibm.com/#/cpt/roadmap/1725


--------AWS Certification Material---------------------------
Amazon Web Services (AWS) Certified - 4 Certifications!

Exam Readiness: AWS Certified Solutions Architect – Associate (Digital) Free
https://www.aws.training/Details/Curriculum?id=20685

Exam Readiness: AWS Certified Developer – Associate (Digital)
https://www.aws.training/Details/Curriculum?id=19185

Free AWS Material
https://digitalcloud.training/amazon-aws-free-certification-training-solutions-architect/

https://aws.amazon.com/certification/certification-prep/


AWS Free Digital Training
https://www.aws.training/LearningLibrary?filters=language%3A1&filters=digital%3A1&tab=view_all


Neal Davis
https://digitalcloud.training/aws-csaa-hands-on-labs-downloads/

AWS Cloud Practitioner Essentials (Second Edition) Prerequsite
Good https://www.aws.training/Details/Curriculum?id=27076


download 
AWS Certified Solutions Architect Official Study Guide


---------AWS Badges---------------------------------AWS Certified Solutions Architect - Associate ----COURSE (skillsoft)----------------------------------------------------------------------
https://learn.percipio.com/channels/783c9bb0-2b77-11e7-9d24-490aed2acd57

1) AWS Associate Solutions Architect 2020: Identity & Access Management
https://share.percipio.com/cd/JrXPzVbEL


---------------------------------------Udemy Ranga AWS Course----------------------------------------------------------------------





------------------------Containers Solutions------------------------------------------------------------
Docker is cloud Neutral

Container Orchestration provides
Auto scaling (scale container based on demand)
Service Discovery (helps Microservice find others)
Self healing (replace failing instances using health check)
Zero Downtime deployments release new versions without downtime

Container Orchestration Options 

1) Cloud Neutral
Kubernetes 
AWS Service = AWS Elastic Kubernetes Service (EKS)
EKS doesn't have a free tier

2) AWS Specific
AWS Elastic Container Service ECS
AWS Fargate (No free tier): Serverless version of AWS ECS



AWS Elastic Container Service ECS (A regional Service)
Need to create a cluster of EC2 instance managed by ECS for Microservice
build using container images

For AWS Fargate 
No need to manage EC2 instances 

Use case 
Microservice
batch processing on ECS using AWS Batch

ECS and Fargate points to Elastic Container Service

Don't Create 

Container definition
Amazon ECS makes it easy to deploy, manage, and scale Docker containers running applications, services, and batch processes. Amazon ECS places containers across your cluster based on your resource needs and is integrated with familiar features like Elastic Load Balancing, EC2 security groups, EBS volumes and IAM roles

Sample Application
Container Name: sample-container-Image
Image: httpd:2.4


A task definition is a blueprint for your application, and describes one or more containers through attributes. Some attributes are configured at the task level but the majority of attributes are configured per container.

Define your service
A service allows you to run and maintain a specified number (the "desired count") of simultaneous instances of a task definition in an ECS cluster.

Service Name: sample-app-service
Number of desired tasks: 2

Application Load Balancer

Configure your cluster
The infrastructure in a Fargate cluster is fully managed by AWS. Your containers run without you managing and configuring individual Amazon EC2 instances.


For Fargate
No EC2 instance created
LB is created
Target Group is created

A Task is a definition of a container
Tasks role can also be attached (RDS)
Task execution IAM role (permission to pull container images)


A existing task deification can't be changed
A tasks has IP and container details

A Service  allows to run and maintain  a specific  no. of tasks  (desired count)
it brought up new tasks in case of failure

ECS Cluster
Groping of one or more container instances (EC2 instances) when   u run your taksk

EC2 instances in a cluster running a container agent for communication

ALB features
Dynamic host port mapping  (multiple task from the same service allowed per EC2 container)
path based routing multiple services can use same listener port on same ALB and be routed based the path


Elastic Beanstalk can run container using Docker as platform but can't create clusters

Amazon EKS 
recommended if you are already using Kubernetes and want to move workload dto AWS

ECR 
Elastic Container Registry
for deploy container images



------------------
To have more access to EC2 instances for ECS
ECS --> Cluster-> Create Cluster -- Select cluster template

EC2 Linux + Networking
Resources to be created:
Cluster
VPC
Subnets
Auto Scaling group with Linux AMI



---------------------------ServerLess-----------------------------------------
You don't worry about  infrastructure
flexible scaling and automated high availability
Pay for use 
No of requests
duration of requests
memory consume

Lambda called/trigger from 
Amazon API Gateway
AWS Cognito
DynamoDB (event)  chnage in DB
CloudFront (lambda@Edge)
AWS Step Functions
Kinesis (event)
S3 Simple Storage Service , new object
SQS (event) new msg in Queue
SNS Simple notification service and so on


name: MyNodeJsLambda1
runtime : Nodejs
create Event: FirstEvent
Test

create environment variable 
EnvironmentName = Development

add beow code in index.js
exports.handler = async (event) => {
// TODO implement
const response = {
statusCode: 200,
body: JSON.stringify('Hello Ali from ' + process.env.EnvironmentName),
};
return response;
};


AWS X-Ray (tracing)
to trace request
request granted for role
Enable it 

Matrix using AWS cloudwatch (monitoring and log)


basic setting
MEMORY = the more memory the more CPU
Price proportional to Memory 

TimeOut  of lambda function  = 3 seconds is default 
max timeout = 15 mins

stateless - store data to S3 or DynamoDB
500 MB of non persistent distk /tmp
Allocate memory in 64MB increments from 128MB to 3 GB


-----------------------------API Gateway-----------------------------------------------------

Rest API Challenges

Management of Rest API is not easy
authentication and authorization
Rate limits (quotas)
Can  Run Multiple Versions of API and multiple environments
Monitor API callsCache API requests
API keys for third party developers  to monitor usage

Warning: don't use API keys for authorisation

Full Managed Service
Life cycle management for REST APIs
Enable Caching for API call with TTL
protect backend by throttling reqest

publish , maintain , monitoring and securing APIs
Integrate with Lambda, EC2, ECS,  or any publicly addressable web servic
Integrate with  CloudWatch, CloudTrails
supports HTTP(s) and web sockets
It is serverless 

HTTP API is new version of REST API


REST API -->  New API
Name: MyHelloWolrdAPI
EndPoint Type: Regional

Regions = 20 
Edge Locations = where regions are not available CloudFront distribute content 200+

Create API

Action-> Create Method -> Get

Integration Type:
Lambda Function: MyNodeJsLambda1
Save
Test

Authorizers
Name:
Type  Congnito and Lambda authorizer (JWT token or SAML)

API keys
To identifying API clients  based on key used for usagePlan

Throttling
wBrust: 800

Quota: 
total no of request in a month

Client Certificates:
to ensure HTTP requests to your back-end services are originating from API Gate
to verify requester's authenticity


Action -> Deploy API 
Deployment Stage:  New Stage
Stage Name:Dev

URL: 	https://ruvdffuyq5.execute-api.ap-south-1.amazonaws.com/Dev

Canary Deployment
sent a % request to a no. of users

Amazon API Gateway 

Authentication

AWS Signature version 4
create a signature using AWS secret access key and send it with API request
if ur users belong to same AWS Account


Lambda Authorizer
Implement a lambda function to authenticate (JWT,OAtuh) and return AMI policies
Integrate with any custom user directory

Amazon Congnito
authenticate mobile and web-apps
want to integrate with web identity providers google, Facebook
MFA ,phone and email versification
support for SAML

Congnito - User pools
create your own secure user directory
create sign -u pages
customisable web UI to sign in with socila sing in option
create a user pool

Congnito - Identity pools
for authorizaion to aws services
connect identity pools with authentication identity providers
own user pool , faacebook,openId, SAML
Federated Identity
an external identity provider

How Congnito works
1) app send users credentials to identity provider (user pool or  facebook)
if ok, it gets a token
2) app send token to identity pool
3) identiy ool validates it via STS and creates temp access keys,secrect key and session token
4) app send a request with these credentials to AWS service


lambda@Edge
running labda functions at end location
lowest network latency for end users

use case: search engine optimisation, W/B testing , dynamic routing
Cab be trigger on AWS cloudFront Events
Viewer request- trigger when request arrive at edge location
Origin request- just before sending request to origin when  obj is not in cache
Origin response-After edge loc receive response back from origin
Viewer Response: just before response is end  back from edge loca
l
Limitations
only supports node.js and python
No free tier and more expensive than lambda

ServerLess Application Model(SAM)
how to test serverless projects with lambda,api gateway and dynaDB in local
its a open source
yaml file with all serverless resourcees, cloud formation template

AWS AppSync
apps cotinue to work offline
data sysnc when connect again
based on GraphQL (FB framework ) get data from multiple api
can integrate with nosQL db, rds and lambda


AWS Step Functions
build distributed applications using vistual workflows

Crate a serverless wotkflow in 10 mins using visual apporch
invoke multiple aws services  into serverless workflows
build workflows as a series of steps
retry a step until it successed
max duration is 1 year
integrate with API Gateway to expose it as API
include human approvals 
long-running
machine leanding models

short duration
iot data ingestion, steam processing
less code
recommend for all new workflows , easy and simple cases

AWS SIMPLE WORKFLOW SERVICE (SWF)
for complex orchestration 
buid and run background jobs
with paralle or sequential steps
synchronously or asynchronously
can invlode human inputs
use case: order processing
workflow can run upto 1 year

Workflow Starter call SWF action to start workflow
eg. order is received
SWF receives request and schedule a Decider

Decider  what is next task to do and return decision to SWF
eg schedule a activity

SWF schedule Activity1
one of those Activity worker pick up Activity1 and send results  to SWF
SWF update workflow history and then schedule another decision task
until decider to close workflows
SWF archivers history and close workflow



-------------------------- Virtual  Private Cloud ----------------READ AGAIN IN DETAIL-----------------------------------------

------------------------------------------Networking -------------------------------------------------------------

VPC is a virtual network or dataset inside AWS for a specific client
Flat in a building but can't go inside other flat
logical isolated
Max 5 VPC in a Region
200 subnets in a VPC
200 routing table
Max 5 Elastic IP in an account (may be extend based on request to AWS)

when we create a VPC the by default below is created automatically
1) DHCP
2) Security Group
3) NACL

VPC is created in a Region and not in AZs
its all properties are regional

can't use same CIDR in other VPC in the same region
but for VPC peering (communicate) both CIDR should be different

Subnet is created in AZ and not in regions
A same subnet can't be used on two AZ

Can a VPC extends to two diff AZs 
No

Can a Subnet exits in two diff AZs 
No

Once a VPC is created, you can't change its CIDR block range

--------------------------
Physical Addressing

MAC address 48 bits

Logical Addressing
eg my home addreess
IP address
IPv4 and  IPv6

IPv4
Public IP and Private IP

32 bit logical address
4 Octet
0 to 255 max value in each octet

IP address = Network ID + Host ID

8 bits  8 bits  8 bits  8 bits 

Large Network
Class A  1.0.0.0 to 126.0.0.0
N H H H 

Class B  128.0.0.0 to 191.255.0.0
N N H H 
Small Network
Class C  192.0.0.0 to 223.255.255.0
N N N H 

Class D  224-239 multi cast4
Class E  240-255 research

Loop Back Address
127.0.0.0 to check network interface

To find network ID

Network bit = 1
Host bit 		 = 0

eg.
115 .0 .0.15
Class A
one oct et is reserved
115.0.0.0  is become the network id

196.10.10.10
then its network id will be 
196.10.10.0

Give IP address find its subnet mask

115.10.10.20
Class A
255 0 0 0 0 subnet mask

160.10.10.20
Class B
255.255 0 .0 is subnet mask

Private IP for LAN no need to buy, can't got to router or internet
Class A 
10

Class B
172.16 to 172.31

Class C
192168.0.0 to 192.168.255.255

Q: 150 10 20 30
Class B
150 10 0 0 Network Id (Identifier of the network)
150 10 255 255 broadcast IP
2 (h) - 2 = 2(16) - 2 = 65534 usable computers can be attached

if both IPs results in same network IP then it means that these are part of same network

Subneting 
network within a network
or locally division of IP addresses

Router interfaces
A different network must be on an Router Interface with diff network ID

router is internet-working device
b/w multiple networks

switch is b/w same network communication

130 10 0  0
		  1
		 2
		 255
130 10 1  0				 
130 10 2  0				 

subnet mask = cidr

A = /8
B = /16
C  = /24   24 bits for Network

OTHER WISE there is Subneting
give host bits to network is called Subneting
dividing  big network into small networks is called Subneting


eg
192  168    1     3      class C  (3N  and1H)
255   255 255  0       subnet mask 
Network address of this will be then 
192   168   1    0       (255= same and 0 = 0)

very good read its screen shots
https://www.youtube.com/watch?v=q7wNcYliJ1Q


CIDR is classless Inter domain routing
A method for allocating IP addresses 

It is as also a 32-bit address, which includes a special number which represents the number of bits that are present in the Block Id.
a . b . c . d / n 
Where, n is number of bits that are present in Block Id / Network Id.
how many bits are turned as 1s


CIDR is 8 for class A by default
CIDR is 16 for class B by default
CIDR is 24 for class C by default  (3N  and1H)
-------------------------------------------------------------------------------------------------------------------

Creating own private network in the cloud
your own isolated network (traffic not visible to other AWS vps)
you can control all the traffic coming in and out a VPC
Best practice all resources from ur VPC

To separate public resource (accessible through internet) with private resources 

create public subnet for public resources and like private
public resources can talk to private 

Each VPC is associated with a Region
each subnet is created in AZ

eg VPC = us-east-1
Subnets = us-east-1a,us-east-1b

VPC -> 
default VPC always created without a name
default subnets also created 

No. of subnets = No. of AZ

IPv4  32 bit  (allows 4.3 billion address) most popular
127.255.255.255

IPv6  128 bit alphanumeric

182.82.143.132/32 is a single ip 
0.0.0.0/0 all

10.88.135.144/30
means
2 rasie power (32 -30) = 4 

Each VPChttp://localhost:7080/mep/services/pcs.ctos.lock.unlock.invoice.ext is associated with a CIDR block
CIDR b;lock can be from /16 (65536 ) to /28 (16) IP addresses

VPC with CIDR block 69.208.0.0/24  69.208.0.0 to 69.208.0.255 

There can't be an overlap of a VPC CIDR block with another connected network

All addresses inside a VPC CIDR range are private addresses
Sbunet resides in VPC

CIDR block of a subnet must be a subset or the same as CIDR block for VPC

Can VPC spread over two regions ?
No

Multiple VPC in same region 
Yes  (default vpc and custom vpc)

Communication b/w tow resources in a VPC is visible outside VPC
No

Can we allow External access to your resources in a VPC
Yes (using Internet Gateway)

Can a subnet spread over two regions ?
No, since subnet is part of VPC and VPC is associated with a single Region

Can a subnet spread over two Availability Zones
No, A subnet is specific to a particular AZ

Can I have 2 subnets in one AZ
Yes , 

Can I have subnet in AZ ap-south-1a if its VPC is in region us-east-1
No, subnet should be on AZ belonging to the VPC's region


VPC Main route table

1) each VPC when created has a main route table by default (enable communication b/w resources in all subnets in a VPC)
2)default roye rule can't be deleted/edited

3)Each subnet can have its route table or share its route tale with VPC
4) Multiple subnets can share a route table
5) A subnet can be associated with one route table ONLY

Security Groups

1) a default SG is created when we created a VPC
allows all outbound traffic
allows communication b/r resources assigned with default security grop
Denies all other in bound (other than default SG)
can be edited but not deleted
EC2 instance by default are assigned  the default security group of the VPC
Security Group can have many to many relationship with Resources (in same VPC)

New security  group
by default No in bound rule
allows all outbound traffic

ssh : 22
rdp : 8889
HTTP :80
HTTPS  :443
PostgreSQL/Aurora :5432
Oracle :1521
MySQL/Aurora/Maria DB :3306
MSSQL  Server:1433
FTP : 21
SFTP : 22



1) Can source/destination of a SG be another SG
Yes


2) A new SG is created and assigned to a DB and Ec2
they can't talk as SG doesn't allow inbound traffic by default

3) A default SG is created and assigned to a DB and Ec2
they CAN talk as SG has a rule allowing traffic b/w resources with same SG

NACL Network Access Control Listener
SG control traffic to specific resources like ec2 ina subnet
NACL control traffic stopping even entering the subnet
stateless firewall at subnet level
Each subnet must be associated with NACL
default NACL allows all inbound and outbound traffic
custom crated NACL denies all inbound and outbound traffic by default
rules have priory no. (lower has high value)

Security Groups
only allow rules
stateful, return traffic is automatically allowed
traffic allowed if there is matching rule

NACL 
allow rules and deny rules
stateless, explicitly allow return traffic
rules are priority , matching rule with highest priority


Traffic from outside subnet then NACL will intercept
Traffic within Subnet SG will intercept

Imp Scenario

EC2 instance can't be accessed from internet
1) does EC2 have public IP address or an Elastic IP assigned
2) Check NACL, is inbound and outbound traffic allowed from your IP to the port
3) Check route table for the subnet, is there a route to internet gateway
if it a private subnet then can't
4) Check Security group, all u allowing inbound traffic from ur IP to the port

AWS Service to allow instances in private subnet to connect to internet to download patches
is using NAT Gateway

A VPC cannot have multiple Internet Gateways


---------------------------------------------IAM -------------------------------------------------------------------------------
Authentication
Authorization
Federated user (externally authenticate users) ie fb, google accounts
very granular control
to perform a single action, on a specific aws resource, from a specify ip , during a specific time window

New group 
Name: Operations
Policy : EC2FullAccess

New User
aws-opsuser-1
Add Group : Operations

Access Key ID and Secret access key is use for CLI

Add permission directly to the user
Attach existing policy directly
AmazonS3FullAccess


Policies
Create Policy
Import Managed Policy
change in JSON   
No aws icon in the custom managed policy

IAM Inline Policies
Create Inline policy
Policy Generator
Add Statement
Apply Policy



cmd
aws configure  (store aws credentials on the ec2 instance which is not a good practice)

aws s3 ls
aws s3 ls bucketName

---Roles---
Talks to S3 from EC2 instance
Create Role
Select EC2
Crete policy
S3RaeadOnly Access
Name; EC2S3AccessRole


Select EC2 instance
Action --> Attach IAM Role
EC2S3AccessRole
Apply

ls ~/.aws  (here keys were stored)
rm ~/.aws/config
rm ~/.aws/credentials

Now
aws configure
don't give access key and secret key

IAM users
users created in AWS account

IAM groups 
Collection of IAM users

Roles 
temporary identities
doest have credentials attached
adv, expire after a set period of time

Policies define permissions (JSON document) 
Permission can be assigned to users, roles , groups
Effect :can have both allow and deny
Resource: 
Action: 
Condition:

* Create a Role assign it permission with talk to S3 Bucket and assign it to EC2 instance

Instance Profile automatically created in background using Management console
Its a container (a box) for an IAM role and used to pass role info to the EC2 instance
Instance profile is a simple container for IAM roles

IAM Scenarios

1) A user in one AWS account wants to access a resource in another AWS account (cross account Access)
ie Dev AWS account , PROD AWS account
Sol: IAM Role


Corporate Directory Federation
1)user authenticated wit a corporate directory,  send token to IAM and get permissions if SAML 2.o complaint direcpty
2)for Microsoft AD then ou can use AWS directory Service
3) set up a custom proxy server to translate user identities from enterprise to IAM roles


IAM - Web Identity Federation

1) authenticate users using we identities 
eg open id (Facebook,google)

2) Amazon Congnito supports login with FB, google or other open id compatible identity providers

3) configure role to use Web Identity as trusted entity
authentication token exchanged using STSAssumeRoleWithWebIdentity API

1) Identity Based policies
attached to IAM User, Group or Role
managed and Inline
Focus: what resource , what action ?
eg. 

User Can list S3 bucket named Bucket1

user access resource directly from is aws account user can switch role 
All services supported

2) Resource Based Policy
attached to resource, S3 buckets, SQS, and AWS KMS keys
Inline Only
Focus: Who (which account, it is public), what action ?
Account A can read and modify
Public can read
cross-account access: user access resource directly from is aws account
subset of  services supported

IAM Scenarios

1) How to rotate access keys without causing problem
create a  new access key
use new access key in all apps
disable original access key
test and verify
delete original key

2) Multiple Permission resolved
By Default Deny (no explicit allow/deny)
if explicitly deny and no explicit  allow then deny
if explicitly allow and no explicit  deny then allow

IMP
IAM users identities exits until thy are explicit ly deleted (no expiration)
IAM allow you to create a password policy
Account Setting --> Set pwd policy
An IAM role can be added to a already running EC2 instance, immediate effective
An IAM role is not associated with IAM user
An IAM role is not associated with long term credentials

when a user , resource or an application Assume a Role, it is provided with temporary credentails

------------------------------Encryption--------------------------------------------
Data States

Data a rest 
in device or backup , in DB

Data in Motion/Transit
being transferred across a network
eg web page content
on premise to cloud
application in VPC talking to DB

In and Out of AWS
With in AWS

Data in Use
active data processed in a  non persistent state
eg. data in RAM

First law of security : Defence in Depth
encrypt all data 
also encrypt data in transit b/w apps and db

Symmetric Key Encryptions
use same key for encryption/decryption

Asymmetric Key Encryption (Public key cryptography)
public key
private key

Encrypt data with public key and decrypt using private key

Most Famous Algo is RSA

KMS 
Key Management Service (a multi tenant service)
manage cryptographic keys both symmetric and asymmetric
define key usage permission including cross account access
track key usage in AWS Cloud Trail (regulations and compliance)
Integrate will all aws services that need data encryption

Automatically rotate master key once in a year
Schedule key deletion
mandatory min wait period 7 days (max 30 days) 
not directly delete the key (either disable it or schedule key for deletion)

Its a managed service 

Console --> KMS --. Create Key
Customer Managed keys
Symmetric
Name: MyMasterSymmetricKey
Key Administrator
Choose the IAM users and roles who can administer this key through the KMS A

Define key usage permissions
Select the IAM users and roles that can use the CMK in cryptographic operations

Console ->S3 Bucket - Crate Bucket -Properties -
Default Encryption
AWS-KMS
MyMasterSymmetricKey

Server Side Encryption with KMS

1) create a customer master key and map to a AWS service (S3)
2) Client upload file to S3
3) S3 ask KMS to provide data keys
4) KMS use Customer master key and generate a new plain data key and a encrypted data key
5) S3 received these keys data and encrypted data key
6) S3 encrypt the data/object using data key with default Encryption Algo
7) S3 stores encrypted data with the encrypted data key in S3
8) S3 delete data key

CMK never leaves  KMS
encryption of data key - KMS using CMK
Encryption of Data - S3 using data key


Decryption

1) S3 send encrypted data key (stored with the encypted data) to KMS
2) KMS decrypt the data key using SMK and send back plain text data key to S3
3) S3 use the data key to decrypt the data

This is called Envelop Encryption 
so KMS use Envelop Encryption 

KMS encrypts small piece of data (data keys < 4KB)
actual encryption is done by the service

AWS service needs IAM permissions to use the CMK

imp:
You can associate a key/ map called encryption context with any cryptographic operation
if encryption key context is different , decryption failed

AWS Cloud HSM

Cloud Hardware Security Module
managed HA and AS
FIPS 140-2 level complaint
it is single tenant
AWS can't access your encryption master keys in CloudHSM
use two or more HSMs in separate AZ in production clusters
AWS KMS can use CloudHSM cluster as "custom key store" to store the keys
use cloudwatch for monitored and cloud trail for tracking key usage
web server offload SSL processing
as certificate authority
digital rights mgmt
TDE for oracle db
if You want a dedicated hardware security module with cloud

All service integrate with KMS and KMS use CloudHSM 

CloudHSM --> Create Cluster
VPC
AZs

KMS -Custom key store and connect it with CloudHSM cluster

All AWS services provides HTTPS endpoints
Encryption is optional with S3 but highly recommend in flight and at rest

Server Side Encryption

SSE-S3
S3 manages its own keys
keys rotated every month
request header

SSE-KMS
Customer managed keys in KMS

SSE-C
customer sends the key in every request 
S3 performs encryption/decryption without storing the key
Https is must

Client Side Encryption
Customer send encryption data to AWS service
Amazon S3 encryption client can be used 


---------------------------------------------CloudTrail , Config and CloudWatch ------------------------
AWS CloudTrail
who made the request
what action performed
what parameter used
what was end result

its like a chnage log 
use case: 
compliance with regulator standards
troubleshooting

deliver log file to S3(default) or cloudwatch log
can setup SNS for log file delivery

Trail Types
1) Multi Region Trail
One trail of all AWS Regions
events from all regions can be sent to one CloudWatch logs log group

2) Single Region Trail
Only event from one specific region
Destination bucket S3 can be in any region

Log files are automatically encrypted with AWS S3 (SSE server side encryption)
S3 life cycle rules can be configure to archive/delete logs
supports log integrity (cant be altered by anyone)

Services - CloudTrail  (its not in the free tier)

Trails -Create trail
name: cloudtrail_mgmgt_events1
All Regions = Yes
Write-only  events

Storage: S3 bucket

Do NOT enable AWS Config and Config Rules if you want to stay in FREE TIER!

----------------AWS Config-----------
Auditing 
creates a complete inventory of our AWS resources
find how resource was configured at any time
configuration of deleted resources would be maintained
history file to s3 bucket every 6 hour
take configuration snapshot when needed

customize config rules for specific resources or for entire aws account
evaluate compliance against desired configuration
SNS notification on configuration change
Group Config rules and remediation actions into conformance packs
can create lambda functions with custom rules
can setup auto remediation for each rule (delete elastic ip which is not used, stop ec2 isntance without a TAG)
Config rules examples (80+ available and custom can be created)

alb-HTTP-HTTPS-redirection-check
Is HTTP to HTTPS redirection is configured on all HTTP listener of ALB

ebs-optimized-instance 
EBS optimization enabled

ec2-instance-no-public-ip
do EC2 having public IP

encrypted-volumes
EC2 attached with EBS encrypted volumes

eip-restricked
are elastic ip used

restricted-ssh
security groups use disallow unrestricted incoming ssh traffic

AWS Config is not free
more rules = more cost


Console - AWS Config
Settings
Rules


---------------------AWS CloudWatch ---------------------

AWS CloudTrail
tracks changes , who made an API call to modify the resource

AWS Config
What did my AWS resource look like a year back
enables you to assess, audit, and evaluate the configuration of your AWS resources

CW is all about Mornington and observability service
informs of logs,metrics and events
set alarms , visualize logs , take automated actions and troubleshot issues

Create DashBoard
Choose Metric
Choose Resource

CloudWatch Alarms (Based on metrics)
related to metrics
you can create alarms on an Amazon EC2 instance CPU utilization
Amazon ELB request latency
Amazon DynamoDB table throughput,
Amazon SQS queue length, or even the charges on your AWS bill
take immediate action

Logs
log groups

Cloudwatch Insights
write queries and get actionable insight from your logs

By default, Amazon CloudWatch does NOT have access to operating system metrics like memory consumption

CloudWatch Metrics


CloudWatch Events  (related to resources)
near read-time stream of systems events that describe changes in AWS resources
related to resources and sends notifications out to targets
eg. 
trigger when someone stop an ec2 instance
call lambda when EC2 starts
notify SNS topic when auto scaling event happs
Also you can schedule events , use unix cron syntax

AWS CloudTrail only records API calls for future references But cloud watch events allow you to take actois



X-Ray is used to trace your application
CloudWatch is used to monitor your application
Cloudwatch SeviceLens monitors issues with Microservice based applications
unified access 

Container Insight
used a pattern called service mesh
monitor,troubleshoot and set alarms for your containerized applications running in EKS,ECS and Fargate

CloudWatch logs
monitor and troubleshoot using system,application and custom log files
monitor for patterns in logs and trigger events based on them 
long term log retention default = forever
archive to s3
Stream to ES Amazon Elastic Search cluster using cloudwatch log subscription

Cloudwatch Logs Agents
Installed on EC2 to move logs from servers to CloudWatch logs

---------------------------------Decoupling Applications -----------------------------------------------------------------------------

Pull Model SQS
Multiple Producers and Multiple Consumers 
Normally same consumers 

produce put messages on queue
**consume pull on the queue only one of the consume will pick  a msg

Scalability
scale consumers instances under high load

Availability
Producer up even if consumer is down

Push Model
Subscribers subscribe to a topic
notification broadcast

Simple Queuing Service SQS
Full Managed, reliable ,scalable Message Queue Service
Unlimited scaling 
Low cost (pay for use , no. of msgs)

max messge size = 256KB
can congifure SSE server account envryption
Lamda trigger can set


Standard Queue
**Unlimited throughput
No order guarantee
No guarantee of exactly one processing 

FIFO Queue
lower throughput 300 msg per seconds
**Order guarantee
Guarantee of exactly one processing 
batch 10 msg per operations then up to 3000 msg per seconds

1) Producer placed a msg on queue
2) globally msg Id is assigned ABCD which is received by the proudcer
3) consumer polls for the msg ,
4) consumer received the msg with ID ABCD and receipt Handle XYZ
5) msg remains on the queue and other consumers can't pool it
6)  consumer process the msg and call delete msg providing receipt handle XYZ
7) message is remove from the queue

Message Life Cycle

Start -> Ready ->   Being processed -> Done
delay second = if configure, the msg will be ready after that time 
if msg is not processed by the consumer after expiry of visibility timeout, then again 
moves to Ready state and to Dead letter queue in case of max Retry policy 

SQS Auto Scaling

SQS -> CW Alarm -> AutScaling -> EC2
use target tracking scaling policy
use SQS metric like ApproximateNumberOfMessages

SQS Important Configurations

1) Visibility Timeout
other consumers will not received a messages being processed for that time
default 30 sec up to  12 hrs
can be changed by call API ChangeMessageVisibility

2) DelaySeconds
time period before a msg is visible on the queue
default 0 sec , max 15 mins
Can be set on queue creation or update using setQueuAttribute

Message Retention period
max period a msg can be on a queue if no one consume it
default = 4 days
min 60 secs
max 14 days

MaxReceiveCount
Max no. of failures in processing a msg to a single Dead letter queue

Other account access to your Queue
SQS Queue Access Policy (resource policy on the queue)

Console --> EC2 -> SQS
SQS 
Configure Queue 
name: First Queue

Create EC2

Create IAM Role
name: EC2RoleForSQS
Create IAM Role , giving access to Queue of SQS then assign to EC2 instance
select EC2
Permission 
AWSLambdaSQSQueueuExectionRole
AWSSQSFullAccess

Go to Running Instances
Action -> Instance Setting --> attach IAM Role EC2RoleForSQS

configure region where Queue are available

cmd on EC2
aws configure
No access key
No secret key
default region = us-east-1

aws sqs list-queue

aws sqs receive-message --queue-url=QUEUEURL 
aws sqs delete message --queue-url=QUEUEURL  --receipt-handle=RECEIPTHANDLE
aws sqs send-message --queue-url=QUEUEURL --message-body="MyMsgfrom cmd line"

Purge Queue
Delete all messages from that Queue

SQS Scenarios

Receiver wants to handle the msg without looking msg body
configure message attributes

Reduce no. of API calls to SQS
use Long polling ie WaitTimeSeconds up to 20 seconds

Receive messages after a week and observe some msg not processed
Exceed msg retention period
default is 4 days
max 14 days

Give High priority for premium customer
create separate queues for normal and premium customer

---------------Simple Notification Service  SNS----------------------------------------------------------------
Publish-Subscribe paradigm (pub-sub)
broadcast async event notification

provides mobile and enterprise messing web services
push notification to apple , android , window devices
send sms to mobile users
send emails

** SNS does not need SQS or a Queue
call allow access to other AWS accounts uinsg SNS policy
can enable encryption SSE

can configure retry policy
can log deliver status
configure roles

SNS - Topic
Create topic
my-firs-sns-topic

create subscriptions
Protocol = Lambda (my first lambda)
Publish Message

Now go to Lambda and see its monitoring , view logs in CW


multiple SQS queues can be subscribed to a same Topic
Applications can send msg to topics where multiple queue are registered and from there labmda function can invoke

Amazon MQ

managed message broker service for Apache ActiveMQ
Amazon MQ = SQS + SNS but with restricted scalability
supports traditional APIS (JMS) and protocols AMQP,MQTT,OpenWire,STOMP
easy to migrate on premises
start Amazon MQ as first step and slowly redesign app to SQS/SNS

use case: 
You have multiple applications in your enterprise using the AMQP message broker. You would like to migrate them to AWS but don't want to do much code changes

--------------------- Routing and Content Delivery -------------------------------------
CDN Content delivery network
distribute content to multiple edge locations around the world
200+ edge locations
High availability and performance
its a content distribution system (used to distribute contents to outside world)

Amazon CloudFront 
serve users from nearest edge loc based on user location
source content can  be S3,EC2, ELB and external websites
if no content found at edge, it will retriever from the origin server and cached at the edge location
can use multiple edge locations
provides features to protect your private content
integrates  AWS shield to protect DDos attacks
integrates  AWS WAF web app firewall to protect SQL Injection, cross site scripting

use cases
static/dynamic websites, audio/video and software downloads , HTTP and rtmp

cost benefits
0 cost of data transfer b/w S3 and CloudFront 
reduce compute workload for your EC2 instances

DNS domain name: which endures can access
Origin: where you get the content from S3,EC2
Cache Control : TTL = 24 hrs. default
configure HTTPS only (default support for both HTTP and HTTPS)
can redirect from HTTP to HTTPS
configure different cloud front behaviour for different URL path patterns from same origion
path pattern: *.php

Signed URLs used for
RTMP distribution (media streaming)
Application downloads (individual files)
situations where cookies are not supported

Singed cookies using key pairs
Multiple files (you have a subscriber website )
doesn't need any change in application URL

Origin Access Identities (OAI)
ensure only CloudFront can access S3
create a special CloudFront user
Create a bucket policy
allow access to S3 only to a spacial CloudFront user

CloudFront is a global service

Console -->CloudFront
Delivery Method --> Web 
OringDomain Name: select your bucket 
Default object: index.html
86400 secs = 24 hours
create distribution  (15 to 20 mins)

the contents will be automatically expire after TTL from the edge locations if not used
InvalidationAPI - to remove object from cache (from all edge locations) for emergencies 

use versioning in object path name

Don't use CloudFront for 
when all requests from a single location 
when all requests from corporate VPN

Scenario: Restrict content to users in certain countries
enable CloudFront Geo restriction
white list(allowed countries)
black list(blocked countries)

-----------------------ETL and Big Data Redshift and EMR---------------------------

Redshift is a petabyte-scale distributed data ware house  based on PostgresSQL
Redshift is a relation database

1) MPP massive parallel processing
storage and processing b/w multiple nodes

2) Columnar data storage

3) High data compression
ie city column

A single row data might be stored across multiple nodes
A query to redshift leader  node is distributed to multiple compute nodes

start with a single node configuration and scale it to multi node 
add / remove nodes dynamically
used mainly for ETL and BI cases
high performance analysis and reporting of large dataset
** supports standard SQL
Integration with data loading, reporting , reporting , Miningsby 
Its a managed service
High available and durability
automatic replication (3 copies of data)
automatic backup (S3 , default retention 1 day, max 35 day)
automatic recovery from any node failure


Redshift cluster

leader node
received sql queries and distributed to compute nodes

Compute Nodes
can be in multiple AZ
no direct access to leader nodes

2) sort keys
data is stored in sorted order using sort key
increase efficiency of your queries
join columns with other tables
timestamp column if u use most recent data  frequently

Aim is to distribute data equal across nodes and minimize data movement during query execution

default strategy= EVEN
KEY = based on values of one column
ALL = entire table on all node ie lookup table

Loading data in Redshift

Simple
SQL insert queries using ODBC and JDBC

Efficient
Redshift COPY command to load data from S3,DynamoDB, EMR

Data Pipelines
Load using AWS Data Pipeline a managed service

On premise data
user Storage gateway or import/export data into S3 
COPY data from S3

Other databases
AWS Data Migration Service
RDS,DynamoDB

Recommendation
prefer COPY over INSERT for bulk operations as COPY is parallel and INSERT is sequential
prefer COPY from multiple files. split into multiple small input files

Managing Redshift workload (WLM)
used to categorize your queries 
create queues and put  queries in it

Redshift Security

integrates with AWS KMS or AWS Cloud HSM
It users 4-tier approach, key based architecture for encryption
1) master key (choose keys in KMS)
2) cluster encryption key (CEK)
3) database encryption key (DEK) 
4)  data encryption key

IAM to manage user permission for cluster operations
grant permissions on a cluster basis instead of per table basis
can add new columns using alter but can't alter existing columns
sql operations are logged against system tables or download to S3
monitor performance and queries with cloud watch and redshift web console
when deleting a redshift cluster, take a final snapshot to S3

Console -> Redshift
fast simple effective data warehouse 

Redshift Spectrum
Run sql queries against datasets in S3
Avro,parquet, csv,json formats supported
Redshift spectrum makes use of metadata to query from S3
scale storage and compute independently
Eliminate expensive data transfer from S3 to data warehousing solutions (cost effective) 
Integrates with AWS Athena
Query against EMR


------------------- EMR Elastic MapReduce --------------------------------------------------------------

Managed Hadoop service with High availability and durability
** EMR give access to underlying OS ie u can ssh into it
Important tools are natively supported
Pig, Hive , Spark , Presto

use cases
log processing for insights
click stream analytics for advertisers
genomic and life science dataset processing

Storage Types

1) HDFS
Standard for Hadoop
Data Storage = EBS or instance (data can lost if instance down)
Persistence Cluster running 24 X 7

2) EMRFS ( Elastic MapReduce File System)
Data Storage = S3
Transient  Cluster running  Infrequent big data jobs (ad-hoc queries)
can directly run map-reduce  jobs

------------------------------------------------------
AWS EMR
For Big data frameworks that needs very large scale data processing and high customizations
machine learning , graph analytics

AWS Redshift
Run complex queries against data warehouse,
housing Structured and Unstructured data

AWS Redshift Spectrum
Run queries directly against S3 without worrying about loading entries data from S3 into a DWH
recommended if u are executing quires frequently against Structured data
You have a huge volume of data in Amazon S3. You would want to run queries against S3 directly instead of moving data to a data warehousing solution

AWS Athena
Serverless (quick ad-hoc queries without working about provisioning a computer cluster)

----------------------Data Lakes ------------------------------------------
simplified big data solutions
Single platform with combination of solutions for data storage , data management and data analytics

Storage 
S3 and S3 Glacier provide an ideal storage solution for data lakes

Data Injection

1) Streaming data (AWS Kinesis Firehose)
transform and store to S3
can execute lambda functions
encrypt,compress, concatenate records to save S3 cost

2) Bulk Data from on-premises
AWS Snowball 
physical device


3) Integrate on-premise data with S3
AWS Storage Gateway


Amazon S3 Query in Place

Run your analytics directly from S3 and S3 Glacier using

1) S3 Select and Glacier Select
SQl queries to retrieve subset of data
supports csv, json, parquet
can use lambda 
Integrates with big data work flows , Presto,hive,spark

2) AWS Athena
Direct ad-hoc SWL query on data stored in S3
Presto,hive,spark,avro

3) Redshift Spectrum
Run queries directly against S3 without loading complete data from S3 in DHW
for structured data

Quick insights from your cold data stored in S3 Glacier ?
use S3 Glacier Select 
store results in S3 buckets

recommendation:
store data in S3 in parquet format
reduce storage up-to 85% and improve querying 
GZIP is recommanded for compression

Apache Parquet is a file format designed to support fast data processing for complex data
Parquet stores nested data structures in a flat columnar format. Compared to a traditional approach where data is stored in row-oriented approach, parquet is more efficient in terms of storage and performance

Analytics with data in S3 data lake

AWS EMR
integrates with S3, use big dta frameworks

AWS ML
create and run models for predictive analytics and ML
data from S3,Redshift, RDS

AWS QuickSight
For visualisation 
data from S3,Redshift, RDS, Athena

AWS Rekognition
Build image recognition capabilities around images stored in S3
use case: face based verification

AWS Data Lakes Data Cataloging
stores format and meta data of the data
in Hcatalog  , hive catalog

AWS Glue 
full managed ETL service
simplify data preparation capture metadata for analytics
connect AWS Glue to your data on Aurora,RDS,Redshift and S3
Glue creates a AWS Glue Catalogue with metadata abstracted from  your data
Run ETL jobs using Spark
metadata from Glue data catalog can be used from 
AWS Athena
AWS EMR
AWS Redshift Spectrum

Handling Data Streams

Characteristics of Streaming Data
Continuously Generated
Small Pieces of data
Sequenced , associated with time

S3 Notifications
process streaming data

eg. take image and customise it with lambda function for different devices in S3
S3 to Lambda is using S3 notification
SNS,SQS or trigger functions on S3 objects
at bucket levels
using prefix and sufix
cost effective 

DynamoDB Streams
each event from DynamoDB  (in a time sequenced order) is buffered 
in a stream near real-time
can be enabled/diabled

EC2 -> DynamoDB -? DynamoDB Streams -> Lambda -> SNS
use case: send email when user registered
streams allow iteration through recotds (last 24 hrs) as batch

Kinesis data Streaming
Primary handle Streaming data
Not recommended for ETL jobs

AWS kinesis Data Firehose
Data Ingestion for streaming data 
Delivery stream
receive
process transform,lambda,compress, encrypt
store  to S3,Elastic search ,Reshift and splunk
Pay for volume of data ingested (serverless)

AWS kinesis Analytics
want real-time intelligence
you can write SQL queries and build Java apps to continuously analyse streaming data
data coming via Kinesis Firehose and Kinesis Data Streams

AWS kinesis Video Streams
monitor video streams from web cams and generate real time alerts

Console -> Kinesis
Data Stream
Create data stream
TestStream
shard: 1

Producers:
putting data in that stream
eg.
kinesis Agent (java client)
AWS SDK
(KPL) Kinesis Producer library

Consumers
get records from Data streams and process them
eg.
Kinesis Data Firehose
Kinesis Data Analytics
(KCL) Kinesis Consumer Library using custom code


--------------------------------------------------------------------------
More Serverless

Serverless Options

Serverless Options : COMPUTE
Aws Lambda
Run code without provisioning servers
Also called FAAS

Lambda @ Edge
Run lambda functions at Edge locations
integrate with CloudFront

AWS Fargate
Container orchestration without worrying about EC2


Serverless Options : STORAGE
S3
Elastic File System

Serverless Options : DATABASE
DynamoDB
Aurora Serverless 
RDS Proxy sits b/w client apps and RDS,  with lambdas , managed  connection pooling

Serverless Options : API PROXY AND ORCHRESTRATION
API Gaetway , API mgmt platform 
AWS Strep Functions , setup workflows

Serverless Options :  Applicaiton Integration and Analytics

Amazon SNS
pub-sub

Amazon SQS
man\ged service

Amazon Kinesis

Amazon Athena
SQL queries on data in S3

Serverless Options : Others

Amazon Congito
Full managed solution providing authorization and authentication solutions
for web/mobile apps

------------------------------------------------------------------------------
Amazon API Gateway Features 




---------------------------VPC Peering--------------------------------------
connect vps each other belonging to same or diff AWS accounts irrespective of the region of VPC
allow private communication b/w connected vpc
request / accept protocol
owner of  requesting VPC send a request
Owner of Peer VPC has one week to accept

* Peering is not transitive A-B-C so not A-C
* Peer VPCs Can't have overlapping address ranges
* CIDR block of each VPC is complete different


us-east-2  (ohio)
VPC 
Launch VPC wizard
VPC with Single public subnet

CIDR =  10.0.0.0/16
Name = custom
public subnet CIDR = 10.0.0.0/24

us-west-1 (north-california)
VPC 
Launch VPC wizard
VPC with Single public subnet

CIDR =  10.1.0.0/16
Name = custom1
public subnet CIDR = 10.1.0.0/24

Peering Connection 
Create peering connection
name: my-vpc-peering

VPC Requester: custom1

Account: Same
Region: us-east-2
VPC Accepter: custom (put its id here)

Action: Accept request

* Route Table configuration
us-west-1 (north-california)
Route Tables
Edit Route

Destination: 	10.1.0.0/16
Target: 	local

Destination: 	10.0.0.0/16
Target: 	Peering connection

on subnet route tables as well

----------------VPC Endpoint ----------------------
Securely connect your VPC to another service

Gateway Endpoint
securely connect to S3 and DynamoDB
endpoint serves as target in your route table for traffic

Interface Endpoint
securely connect to Aws services other than S3 and DynamoDB
powered by PrivateLink (keep traffic wintin AWS network)
need ENI as entry point for traffic

Avoid DDoS, as traffic not go thru internet
Simple, Don't need Internet Gateway, VPN and NAT

---------------VPC Flow Logs -------------
Monitor network traffic
troubleshoot connectivity issues (NACL)
capture traffic going in and out of your VPC
Flow logs can be created for VPC,subnet or Netowrk Interface
publish to Cloudwatch or S3
Contains Accept or reject 

SG is stateful ie if inbound is allowed, outboud is automatically allowed

User --> NACL -->Subnet --> Security Group --> EC2

Inbound Traffic rules
if inbound request is rejected, NACL or SG could be mis-configured
if outbound response is rejected, NACL is mis-configured

Outbound Traffic rules
if outbound request is rejected, NACL  OUT or SG  OUT could be mis-configured
if outbound response is rejected, NACL OUT is mis-configured

if problem with request -> problem with NACL or SG
if problem with response -> problem with NACL

----------------------------AWS and On-Premises -------------------
Are there any programs/projects available for cloud where one can have hands-on experience on real projects working with cloud experts ?

AWS MANAGED VPN
IPsec VPN tunnels from VPC to Customer Network
over internhttps://w3.ibm.com/w3publisher/ibmaot
et is encrypted ysing IPsec protocl
VPN gateway to connect one VPC to customer Network
Customer Gateway installed in customer network and u need a niternet routable IP address of cusomer gateway

AWS Direct Connect (DC) 
Private Dedicated Network
can reduce ISP{ bandwidth costs
direct line from AWS to your Data Center
Connection options
dedicated 1 GBPS or 10 GBPS
Hosted : shared 50 MBPS to 10 GBPS

* Establish DC can takes more than a month
* Establish redundant DC for max reliability
* DC doesn't encrypt data , (private connection only)

AWS Direct Connect  Plus VPN
IPsec site-to-site VPN tunnel from an direct connect location to
customer network
Traffic is encrypted using IPsec protocol

On AWS you connect to Direct Connecf and then DC to VPN to customre data center

Software VPN
Fully managed both sides of AWS VPC connectivity
Run software VPN appliance in your VPC
recommanded for Compliance as you need to manage both sides of the connectio
Recommended when u use gateway devices which are not supported by AWS VPN
u responsible e for patches and updates
and its become a single point of failure

AWS VPN CloudHub
when u need network connectivity b/w your multiple banch offices
CloudHub can be connect on Direct Connect or via VPN
install Virtual private Gateway at AWS and Customer Gateways in customer offices


VPC Flow Logs
service helps you to troubleshoot network connectivity issues

-------- Moving Data b/w AWS and on-premises------------------
data migration

S3 transfer Acceleration
when transferring less data up to few TB
basic option
uses cloudFront edge locations
Enable S3 transfer acceleration and use endpoints

AWS Snowball
transfer dozes of TB to Petabyte from on-premises
physical shipping
request the snowball from console
100TB  (80 TB usable)per appliance
all data is automatically encrypted
choose snowball if data transfer takes over a week based on your network connection
eg. 5TB can be transferred on 100Mbpc line in a week at 80%utilization

AWS Snowmobile
peta byte of data
100 PB storage per truck
data is automatically encrypted with KMS (AES-256)

AWS DataSync 
Transfer file storage to cloud
secure
10 X faster of TB to/from AWS over internet or AWS direct connect
transfer from on premise file storage (NFS,SMB) to S3, FRx
Integration with AWS storage Gateway for ongoing update
use case: Data Migration,replication and clod data archival


Alternatively, use S3 transfer acceleration if apps integrated with S3 AP1 

------AWS Data PipeLine--------------------------------------
automate data processing pipelines b/w S3,RDS , DynamBO,EMR and On-preimieses

On-Primise DB ->  S3 ->EMR->S3->redshift

* Create COMPLEX DATA PROCESSING WORKLOADS that are FAULT Tolerant
repeatable and Highly available
Launches required resources and tear them down after execution
*** It is not for Streaming Data

----------- Database Migration Service ---DMS-------------------
migrate databases to AWS
Homogenous (Oracle to Oracle) preferred 
Heterogeneous (Oracle to Aurora)
free for first 6 months when migrating to Aurora,redshift or DynamoDB
use case: 
consolidate multiple DB into a single target database
DMS is for smaller workloads (less than 10TB)
* continuous data replication for DR

------AWS Schema Conversion Tool --------SCT-------
It is a part of DMS
preferred option for migrating data warehouse data to Redshift
Migrate DB schema
SCT assessment report
update source code    
Fan-in (Multiple Source- Single Target) 
Fan-out (Single Source- Multiple Target)
SCT is preferred when schema conversion are involved
SCT is preferred for large data warehouse workloads (migration to Redshift)
No data replication for DR

-----------------------DevOps----------------------------------------------------

AWS CodeCommit
private source control (based on Git)

AWS CodePipeLine
Orchestrate CI/CD pipelines

AWS CodeBuild
Build and Test code (application packages, containers)

AWS CodeDeploy
Automate Deployment (EC2,EKS, lambda etc)

Infrastructure as a code IAAC
treat infra as the same way as application code
track your infra changes over time (version control)
being repeatability into your infrastructure

2 key parts

1) Infrastructure Provisioning
provisioned compute,db,storage,networking
open source, cloud neutral, Terraform
AWS service: CloudFormation

1) Configuration management
Install right software and tools on provisioned resources
AWS Service: OpsWorks lets you use Chef and Puppet to automate how servers are configured, deployed, and managed across your Amazon EC2


---------AWS CloudFormation  -----------------

Automate deployments and modification of AWS resources in a controlled and predictive way

avoiding configuration drift (less error prone)
all configurations in a simple txt JSON or YAML
CloudFormaion handles dependencies
eg. first VPC then subnets and then db
Automatic Rollback
Free to use , pay for resources provisioned
get an automated estimate for your configuration


CloudFormation Templates
JSON/YAML defining multiple resources

Stack
group of resources that are created from CF template

Change Sets
to make changes to the stack, update the template
tells what whould chnage if you execute
allows u to verify the changes and then execite

Resources
what u want to create
One and only mandatory element

Parameters
values to pass to your template at runtime
ie "t2.micro"

Mappings
key value pairs
configure diff values for diff regions

Outputs
Return values from execution
eg. id of resource



CloudFormation VS Elastic Beanstalk

CloudFormation
Deleting stack will delete all associated resources 
except DelitoinPolicy set to "Retain"
or you caexaecn enable Termination policy for the entire stack
Template stored in S3

use CloudFormation StackSets to create/update/dele stack across multiple accounts and regions
with a single operation

Elastic Beanstalk
like a pre packaged cloudformation template with a user interface
and in background cloudformation template is created and executed

AWS OpsWorks
is a Configuration Management Tool
Managed service based on Chef and Puppet
eg. copy a file 10 100 servers
make a change across 100 servers
both on preimies and on cloud

Configurations resides at 
Chef recepies/cookbooks
Puppet manifest

All metric send to CloudWatch
All configuration mgmt tools can also do
infrastructure provisions but not recommended


-----------------AWS Certification FAQ -------------------
Understanding Data Transfer Cost

using public IP address for communication b/e EC2 instances can get expensive
use private IP address

Data transfer is free with same AZ
Ec2,RDS,Redshift,ElasticCache,ElastiC Network Interface

Data transfer is free with same AZ
between EC2 and S3,G\lacier,DynamoDB,SNS,SWS,Kinesis

Best Practice: Maximize traffic that stays with an AZ 

High Availability 
Req: need 2 EC2 instances running all the time in single region
2 EC2 instance in AZ1 and 2 in Az2

Req: need 4 EC2 instances running all the time in single region
2 EC2 instance in AZ1 and 2 in Az2 and 2 in Az3

Fault Tolerance means zero chance of failure 
extra safe

Req: need 2 EC2 instances running all the time in single region
ie place instances in diff subnets
2 EC2 instance in AZ1 and 2 in Az2 and 2 in Az3

AWS Shield
shields from distributed denial of service attacks DDoS
eg. sending million request to the server
protect Route S3,CloudFront,Global Accelerator,EC2,ELB

AWS Shield Standard 
Zero cost
automatically enabled
layer 3 and 4

AWS Shield Advanced
paid service
24X7
protect your AWS bills from usage spikes

AWS WAF  Web Application Firewall
protect web applications from OWASP to 10 (Open web application security project)
most critical and common security risks to web apps
CVE (common vulnerabilities and exposure)
can be deployed on CloudFront,ALB,API Gateway
web traffic filtering, block attacks

Manage AWS Accounts
diff accounts for diff env and diff business units
centralized management,billing, security, compliance

AWS ORGANIZATIONS
Organize accounts into Organizational UnitsOU 
centralized compliance mgmt for AWS config rules
Send AWS CloudTrail Data to one S3 bucket (across accounts)
AWS Firewall Manager to manage firewall rules across org accounts
WAF,Shield Adv protection, security groups
**Service Control policies SCPs to define restrictions across accounts
eg. 
prevent users from disabling AWS config or rules
EC2 is always of specific type
require MFA to stop EC2 instance
require to have a must tag  on a resource

AWS RESOURCE ACCESS MANAGER
share resources with any AWS account or within your AWS org
eg.
AWS Transit Gateways
subnets
AWS License manager configurations
S3 Resolver rules
it reduced operational overhead and optimized costs

AWS TRUSTED ADVISOR
recommendations for cost optimization, performance, security and fault tolerance
All AWS customers get 4 checks free
1) service lints
2) SG\ having unrestricted access
3) Proper use of IAM
4) MFA on Root Account


Business or Enterprise AWS support plan provides over 50 checks
ie
how much u saved with reserved instances
resource utilization look like ? are u right sized  for ur load ?

Recommendations by Trust Advisor

Cost Optimization
highlight unused resources
opportunities to reduce costs

Security
Settings that make sol more secure

Fault tolerance
Increase resiliency 
redundancy improvements, over utilized resources

Performance
Improve speed and responsiveness

Service Limits
identify if service usage > 80% of service limits

AWS SERVICE QUOTAS
AWS account has regional-specific default quotas or limits for each service
aService Quotas allows you to manage your quotas /limits for over 100 AWS services
from one location

AWS Directory Service
user data mgmt service
It provide AWS access to on-premise users without IAM users

Option1: AWS Directory Service for MicrosoftAD
more than 5000 users
Trust relationship needed b/s AWS and on-premise directory

Option2: Simple AD
less than  than 5000 users
powered by Samba4
Doesn't support Trust relationship with other AD domains

Option3: AD Connector
use your existing on-premise directory with AWS cloud services
your users use existing credential to access AWS resources

AWS Global Accelerator  (Again)

Direct traffic to optimal endpoints oover AWS global network
Provides two static IPs from AWS edge network
Distribute traffic across multiple endpoint resources in multiple AWS regions
works with ALB,EC2,Elastic IP

AWS Elemental MediaConvert

new video transcoding service
convert multiple media formats
high quality video processing workflows

AWS Elastic Transcoder
create WebM video,Mp3 audio or animated Gif
For all other video processing use cases, recommanded to use Element MediaConvert

AWS Elemental MediaLive
For live video processing

AWS Macie
Fully managed data security and data privacy service
*Automatically discover,classify and protect sensitive data in S3
use AI and ML

AWS Workspaces
Desktop as a Service (DaaS)
replacement for VDI (virtual Desktop infrastructure)
provision windows or Linux Desktop in minutes

AWS System Manager Parameter Store
manage application environment configuration and secrets
ie database connections, password
supports Hierarchical structure
store config at one place for multiple apps and environments  
maintain history of configuration over a period of time
integrate with KMS,IAM,CloudWatch and SNS

AWS Secret manager
rotate , manage and retrieve database credentials , API keys and other secrets for your applicaitons
Integrate with KMS,RDS,Redshift and DynamoDB
*Rotate secrets automatically without impacting applications
*service dedicated to secrets management
* recommended for workloads needed HIAA,PCI-DSS compliance

Simple Workflow Service (SWF)
background jobs parallel o


AWS Single Sign on
single account to access multiple websites
centrally manage SSO access to all of your AWS accounts
Microsoft AD integration
SAML
Integration with AWS Organization
One place  auditing in AWS CloudTrail

AWS Elasticsearch
managed service around Elasticsearch
support ELK stack
elsticsearch
logstach to inject data
Kibana for dashboard visualization
use case: 
fast serach
app/server  monitoring get intelligence from you logs

---------Well Architect Framework ----------------------

PILARS

1) OPERATIONAL EXCELLENCE PILAR
To avoid/minimize effort and problems with
Provisioning servers
Deployment
Monitoring
Support

Recommendation
Use Managed Services (no worry about managin server,availability,durability)
Go serverless (prefer Lambda to EC2)
Automation with CloudFormation 
Implement CI/CD to find problems early (codepipeline,codebuild,codedeploy)
Perform frequent,small reversible changes

3 Stage approach AWS Recommend

1) PREPARE: for failure
simulate failure 
game days 
Disaster recovery exercise
Implement Standards with AWS config rules

2)OPERATE: gather data and metrics
cloudwatch (logs agents)
config, config rules,
cloud trail
VPC flow logs
X-Rays (tracing)

3) EVLOVE: Get Intelligence

use Amazon Elasticsearch to analyze logs

2) SECURITY PILAR
IAM, AWS Shield, WAF,KMS, HSM

a. PRINCIPLE OF LEAST PRIVILEGE for least time
use temporary credentials when possible (IAM roles, Instance profiles)
use IAM groups to simplify IAM management
Enforce strong password policies
Enforce MFA
Rotate credentials regularly

b. SECURITY IN DEPTH - Apply security in all layers
VPS and Private subnets
Security Groups
NACL
use hardened EC2 AMIs (Golden Images)
use CloudFornt with AWS sheild for DDoS
use WAF with CloudFront and ALB
Use CloudFormation (enforce security via scripts)
Protect data in Transit and at rest
Actively monitor for security issues
Centralize security policies for multiple AWS accounts

c.Protecting DATA AT REST
enable versioning 
enable encryption KMS and Cloud HSM ,(rotate encryption keys)

S3
SSE-C,  SSE-S3,   SSE-KMS

DynamoDB
Encryption client, SSE-KMS

Redshift
KMS and AWS CloudHSM

EBS, SQS and SNS
KMS

RDS
KMS, TDE

d.Protecting DATA IN TRANSIT	
data coming in and out of AWS
by default All AWS API use https/ssl
perform client side encryption 
Ensure your data goes through AWS network as mush as possible
VPC endpoints and AWS Private link

e: Detect Threats
actively monitor security issues
Monitor CloudWatch logs
use GuadDurty to detect threats and contiguously monitor malicious behaviour 
use AWS Organization to centralize security policies 	


2) Reliability PILAR
It is about how quickly you recover from Infrastructure and application issues
How quickly you adopt changes demands in load

Automate recovery from failure
health checks and auto scaling
managed services like RDS  automatically switch to standby

Scale Horizontally
Maintain redundancy
multiple Direct Connect connections
Multiple regions and AZ
Prefer Serverless
prefer loosely couple architecture
SNS,SQS

Distributed system best practices
API Gateway for throttling requests

Loosely coupled architecture
ELB
as users are not tied to EC2
SQS
SNS publish subscribe
Amazon Kinesis
handle event streams, multiple clients

Troubleshooting on AWS

S3 server access logs
S2 data request details,request type,date time
Troubleshoot bucket access issues and data requests

ELB Access Logs
Client IP,latencies and server response
analyse traffic pattern and troubleshoot network issues

AWS VPC Flow Logs
monitor network traffic
troubleshoot network connectivity and security logs

CloudWatch
monitor metrics from AWS resources

CloudWatch logs
logs from various errices, debug app issues

CloudConfig
AWS resource inventory, history , rules

AWS CloudTrail
History of AWS API calls , cli,sdk
auditing and troubleshooting, who did what and from hwere-

Shared Responsibility Model
Security and Compliance is shared responsibility b/w AWS and Customer

AWS responsible for  Security OF the cloud
Customer responsible for  Security IN the cloud


using EC2 instance is IAAS 
AWS only responsible for infrastructure only

Managed Services
S3,DynamoDB
AWS Manages Infa,OS and Platform

3) PERFORMANCE PILAR
meet needs with minimum resources (EFFiciency)
Use Managed services
Go Serverless (Lower cost)
Monitor performance
CloudWatch Alarms


EFFiciency use right solutions
Compute: EC2 VS Lambda VS Containers

Storage
Block, File , Objects 

Database
RDS VS DynamoDB VS Redshift (big data and relationsal)

Caching
ElastiCache (front end to DB) VS CloudFront (contents server from edge) VS DAX (cache infront of Dynamo DB) VS Read Replics (reporting apps to run) 

Network
CloudFront, Global Accelerator, Route 53, Placement Groups, VPS endpoints , Direct Connect

Product specific features
S3 Transfer acceleration , EBS optimised instances

4) COST OPTIMIZATION PILAR
match supply and demand
implement auto scaling stop dev and test resources when don't need
go serverless
Track you expenditure
cost explorer
aws budget 
use tags on resources

Right Sizing
Trusted advisor for recommendations
On demand Vs Reserved VS spot instances
AVoid expensive sols: MySQL VS Autrora VS Oralce
AWS Direct Connect (save internet cost)
CloudFtont  reduce load on backbend system


X-Rays traces a request between API Gateway and Lambda functions

Certification Reading
AWS Architecture Center
***AWS FAQS

During register
Accommodation Type: ESL + 30 mins
wait for it to approval


--------Recommendations -----
Keys parts in questions
Features: serverless, key value,atuo scaling
Qualities: cost effective, high available , fault tolerant

Skip wrong answer
















