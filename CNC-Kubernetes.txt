
****************************************************** KUBERNETES **************************************************************************
Micro services
decoupled applications

Complexity
1) Difficult to configure
2) Managemnt 

Kubernetes orchestration tool
automated deployment features
hardware failover scheduling
communication b/w applications

Google made it 
Initial name Borg then Omega
2014 open source

Kubernetes Master (Control Plane) gets the requests
control state of the cluster

Master Components 

1) etcd  distibuted data store 
having config of cluster , nodes address, applcaiton deplyed
key value pair

2)Scheduler
Resource requirement of the appp
resource management

3) Controller Manager
control worker nodes as well
apllicaiton managment 
replicas 
where to deploy
failover

3) API Server  
communicate with client 
ack as a communication bridge


Kubernetes Worker Nodes
machines that actual run the application

Worker Node Component 

1) kube-proxy
application bridge for communication b/w 
multiple applications
load balancing

2) Container Runtime
to run container
image to replicas

3) kubelet
make sure instance is made of using configurations
check health


Hitting a moving target
move application from server1 to other server1

one of the node failed
resource utilisation

If multiple container provides same service then 
you can group them at a single static IP address
which remain the same.

minikube
tool make worker and master node 
one node one master setup
tool to help us kubernetes to run in our system
for development purpose


Kubectl
kubernetes client

----------------------------------Install Minikube and kubectl---------------------------------------------------------------------------

https://computingforgeeks.com/how-to-install-minikube-on-ubuntu-debian-linux/


sudo apt-get update
sudo apt-get install apt-transport-https
sudo apt-get upgrade
sudo apt install virtualbox virtualbox-ext-pack

wget https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
chmod +x minikube-linux-amd64
sudo mv minikube-linux-amd64 /usr/local/bin/minikube

--------------------------------------------------------------------------------------------
VirtualBox runs virtual machines.
Minikube is a Kubernetes-specific package that runs a local development Kubernetes cluster on VirtualBox.
kubectl is the command line tool that lets you interact with your Minikube Kubernetes cluster.

Get my book on Kubernetes for software developers, used by engineers at Google, Microsoft, and IBM.



--------------------------------------------------------
curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl

chmod +x ./kubectl

sudo mv ./kubectl /usr/local/bin/kubectl

kubectl version --client


---------------------------------
chage to ubuntu user 

minikube start
minikube status
kubectl cluster-info

-------------------------------------------------------
Nodes
kubectl get nodes or  kubectl get no
kubectl describe nodes NODENAME
kubectl describe nodes minikube 


Alias

alias kgn="kubectl get nodes"
kgn

PODS
Application must be in containerised
wrapper around container called pod (like virtual machine)
each pod having its own ip and hostname and its processes
Kubernetes ensure that A pod having (1 or more container) to be deployed in one worker node only

when two or more container needs to 
group together to achieve a task

rule
container is to perform a single task
low size
quick load

pod gives a feel that all processes running in it 
is executing in a single container

volume can be shared b/w containers  in a pod
that is why one node one pod

No same port no assign in a pod to difff container
but can be on a diff pod
as each pod has diff IP

Grouping Pod

sudo apt-get install cpu-checker
sudo kvm-ok 


minikube start --driver=virtualbox --force
minikube start --driver=docker --force


minikube start --driver=virtualbox
minikube config set driver virtualbox

*************Minikube KataCoda*********************

Minikube is a tool that makes it easy to run Kubernetes locally. Minikube runs a single-node Kubernetes cluster inside a VM on your laptop for users looking to try out Kubernetes 

minikube version

Start the cluster
minikube start --wait=false

kubectl cluster-info

kubectl describe node minikube

kubectl get nodes
This command shows all nodes that can be used to host our applications

alias KGN="kubectl get nodes"
KGN

kubectl get nodes or kubectl get no

-------------------------------------------

pods is like a  virtal machine

one pod for one worker node
pod helps to group multiple containers together
its not a good approch to put all containers inside a single pod as kubernates ensure that it will deploy this pod on a single worker node, hsece resouce utilisation and load sharing is not good .

Grouping Pods
if
container should wo
rk together
user reach the containers together

POD Defination
YAML (user friendly)
JSON


Resources
Pod
Deployments
Jobs
Others
----------------------------------------------------------
Creating a POD

nano myfirstpod.yaml

myfirstpod.yaml                             
kind: Pod
apiVersion: v1
metadata:
  name: myfirstpod
spec: 
 containers:
  - name: container1
    image: aamirpinger/helloworld:latest
    ports:
    - containerPort: 80 

-----------------------------------------------------------
kubectl create -f myfirstpod.yaml

kubectl get pod or kubectl get po

NAME         READY   			STATUS    RESTARTS   AGE
myfirstpod   1(1=ready)/1(no. of container)     Running   0          9m29s


kubectl get pods myfirstpod -o yaml
kubectl get pods myfirstpod -o json

kubectl describe pods myfirstpod


Port Farwarding

kubectl port-forward myfirstpod 6100:80

http://localhost:6100

Ctrl + C will stop the port forwarding means
applicatkion still running but can't accessabile


creating a pod from 

kubectl run mysecondpod --image=aamirpinger/flag:latest --port 80 --restart=Never 

kubectl port-forward mysecondpod 6101:80
http://localhost:6101

using volume we can share files directories between containers within the pod

pod ip address and container port no is required.

we can create mutiple copies of our app/container as it gives static ip for each pod
also load balance

----------------Labels-----------

 helps to group resources
organise pods with help of label
key/value 

---------------------------------------------------
kubectl create -f myfirstpodwithlabels.yml

kind: Pod
apiVersion: v1
metadata:
  name: myfirstpodwithlabels
  labels:
    type: backend
    env: production
spec:
  containers:
  - image: aamirpinger/helloworld:latest
    name: container1
    ports:
    - containerPort: 80
    
    
kubectl run myfirstpodwithlabels1 --image=aamirpinger/flag:latest --port 80 --restart=Never --labels=type=frontend,env=development


kubectl get pods --show-labels

show lables in cloumns
kubectl get pods -L env,type,run

assgin lables at runtime

kubectl get pods --show-labels

add a label
kubectl label pods myfirstpod app=helloworld type=frontend

chnage a label
kubectl label pods myfirstpodwithlabels1 env=production --overwrite=true

remove a lable
kubectl label pods myfirstpod app-filter

pods with lable selector (select pods based on the criteria/ )

kubectl get pods -l type=frontend --show-labels
kubectl get pods -l type!=frontend --show-labels


kubectl get pods -l 'type in (frontend,backend)' --show-labels

kubectl get pods -l 'type notin (frontend,backend)' --show-labels

kubectl create -f myfirstpod_selector.yaml

kubectl get pods podwithnodeselector -o yaml
didn't match node selector on the worker node
thats why it is in pending state

Assing a label to a worker node
kubectl label node minikube typeofharddisk=ssd

Note: 
typeofharddisk=ssd should match in yaml file

----------------Annotations-----------

kubectl annotate pod myfirstpod app-desc="this is example of annotation in kubernetes"

kubectl get pods podwithannotation -o yaml

---------------Describe Pods Insight --------------------------------------------

kubectl describe pod myfirstpod

--------Overlapping Labels using Namespace ------------


 is a kind of virtulbox which islolate self contain resources with other namespace. 
Kubernetes groups objects into namespace


kubectl create namespace production 

kubectl create -f myfirstpodwithNS.yaml
kubectl get pods --namespace=production

kubectl run podwithnamespace1 --image=aamirpinger/helloworld --port=80 --restart=Never --namespace=development

--------------------------------------------------

kubectl create deployment first-deployment --image=katacoda/docker-http-server

kubectl get pods

One possible solution is NodePort, that provides a dynamic port to a container.
kubectl expose deployment first-deployment --port=80 --type=NodePort

minikube addons enable dashboard

Kubeadm solves the problem of handling TLS encryption configuration, deploying the core Kubernetes components and ensuring that additional nodes can easily join the cluster. The resulting cluster is s

The master is responsible for running the control plane components, etcd and the API serve

Listing Pod from All Namespaces

kubectl get pods -n development
--------------------------------------
kubectl get pods --all-namespaces


*****************Lesson 3 ReplicaSets, Jobs and CornJobs*****************************

ReplicaSet is a resource
create and make sure multiple copies of applciations

ReplicaSet notice the missing pod and creates a replacement pod
if the pod is created using ReplicaSet

ReplicaSets

1) label selector
gropup pods based on labels

2) Replica Count
No of copies

3)Pod template
configurations used to create new pod

--------------------------
Creating ReplicaSet
nano rs.yaml
pod name is random generated in metadata

create a yaml file for creating repicaset
kubectl create -f rs.yaml

kubectl get replicaset
OR
kubectl get rs 

kubectl get pods --show-labels

kubectl get rs my-replica-set -o yaml


kubectl describe  rs my-replica-set
kubectl get rs,pod

kubectl delete pod my-replica-set-6qqrj
it automatically creates another based on the replication factor

if we chnage lable of a running pod
kubectl label pod my-replica-set-9pmm7 app=rsexampleNew --overwrite

then another pod with label app=rsexample
will be created automatically and the mgmt of the updated label is not managed by ReplicaSet
as its label does't match


-----Deleting Pods and Replica Sets------------------------------------

delete all pods and it should not create automatically

kubectl delete pods -l app=rsexample
kubectl get po,rs

SO We need to remove the RepilaSet then its pods will also be deleted
kubectl delete rs my-replica-set

What if we want to delete the ReplicaSet and Not the pods then
kubectl delete rs my-replica-set --cascade=false

NOW pods are running individualy without managed by replicaSet as we 
deleted it 

Now rs is deleted 
rename app=rsexampleNew to app=rsexample
kubectl label pod my-replica-set-9pmm7 app=rsexample --overwrite

kubectl get po
it will show 
NAME                    READY   STATUS             RESTARTS   AGE   LABELS
my-replica-set-9pmm7    1/1     Running            1          16h   app=rsexample

now if execute below command it will create only two 
new pods and one with same label already exits

kubectl create -f rs.yaml

NAME                    READY   STATUS              RESTARTS   AGE   LABELS
my-replica-set-9pmm7    1/1     Running             1          16h   app=rsexample
my-replica-set-kdxgv    0/1     ContainerCreating   0          9s    app=rsexample
my-replica-set-sx6vb    0/1     ContainerCreating   0          9s    app=rsexample

-------------------------------------------
 selector:
    matchLabels:
      app: rsexample
-------------------------------------------         
   
   matchExpressions:
    - key: app
      operator: In
      values:
      - rsexample1
--------------------------------------------------
Modifying ReplicaSet

At runtime

1) on chnaing replicas value pod count chnage instateneouly

2) lebel selector template does't change at once

-----------------
chnage rsource configurations at runtime

kubectl edit rs my-replica-set

----Scaling ReplicaSet-------------------
kubectl scale rs my-replica-set --replicas=5

--------Job Resources--------------------
tasks to perform and terminate the pod
it is basically a pod
creates one or more pods and ensure that a specified no. is successfully terminated


if job resource is deleted then its pods deleted

example:
 need to run a applciation , perform a taks then delete that applciation
 so job resource is used
 like bank day end routine

If a job is failed then 

restartPolicy: OnFailure
container is restarted

 restartPolicy: Never
 here  new container created to complete the job
till backoffLimit: 4

kubectl get job

kubectl logs <podName>
kubectl logs jobexample1-4hrp2

will display the cosole output of the container in the pod

---------------CronJob-------------------------------
kubectl create -f cronjob.yaml

NAME                     SCHEDULE    SUSPEND   ACTIVE   LAST SCHEDULE   AGE
cronjob.batch/cronjob1   * * * * *   False     0        55s             3m36s

NAME                            COMPLETIONS   DURATION   AGE
job.batch/cronjob1-1592925240   1/1           12s        2m55s
job.batch/cronjob1-1592925300   1/1           6s         115s
job.batch/cronjob1-1592925360   1/1           6s         55s
job.batch/jobexample1           1/1           7s         34m

NAME                            READY   STATUS             RESTARTS   AGE
pod/cronjob1-1592925240-vvcv6   0/1     Completed          0          2m55s
pod/cronjob1-1592925300-9dtbb   0/1     Completed          0          115s
pod/cronjob1-1592925360-l5cpq   0/1     Completed          0          55s


kubectl delete cj cronjob1

* * * * * every minute
minute 0-59
hour   0 to 23
day of month 1-31
month of year 1-12
day of week 1-7 Mon-Sunday

*/15 **** every fifteen minute

0 means once 

0 5,17 means 5am and 5pm

5-17 means monday,tue,wed,thur,fri,say

 0 */15 is every 15 minute

** */2 alternate days

--------------Lesson 4 Services and Probes-----------------------------------

Service Resource
single entry point to access all grouped resouces
provides a static IP of grouped resources
static IP exist till the service exists

Types

1) Cluster IP
internaly communication
frontend to backend
It exposes the service on an internal IP in the cluster
This type makes Service only reachable from within the cluster
check it using minikube ssh and clsuterIP:port
gives static IP and can't access from outer world
by default



2) NodePort
port no is assigned 30000 32767
all worker nodes where pods are grouped 


3) LoadBalancer
external ip for external world
assign a fixed external IP to the service




4)ExternalName
Like linux Alias command

can be chnaged at runtime hence no effect on the applciation 

like db string

kubectl create -f lb-service1.yaml

kubectl get svc  or get services

kubectl create -f lb-service1.yaml

kubectl get svc
NAME          TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
kubernetes    ClusterIP      10.96.0.1      <none>        443/TCP          29d
lb-service1   LoadBalancer   10.99.209.60   <pending>     8080:31694/TCP   93s

minikube ip
192.168.99.100

http://192.168.99.100:31694

creating service using command line

kubectl get po,rs --show-labels
NAME                        READY   STATUS             RESTARTS   AGE   LABELS
pod/jobexample1-4hrp2       0/1     Completed          0          23h   controller-uid=989e8733-aa7f-4cc1-b47c-abe45e3fd3ae,job-name=jobexample1
pod/my-replica-set-dsb47    1/1     Running            0          13m   app=rsexample
pod/my-replica-set-kk7qs    1/1     Running            0          13m   app=rsexample
pod/my-replica-set-wnhvv    1/1     Running            0          13m   app=rsexample
pod/my-replica-set1-8l96l   1/1     Running            3          24h   app=rsexample1
pod/my-replica-set1-kfj9s   1/1     Running            3          24h   app=rsexample1
pod/my-replica-set1-lz927   1/1     Running            3          24h   app=rsexample1
pod/myfirstpod              1/1     Running            15         28d   type=frontend
pod/myfirstpodwithlabels    1/1     Running            15         28d   env=production,type=backend

AME                              DESIRED   CURRENT   READY   AGE   LABELS
replicaset.apps/my-replica-set    3         3         3       13m   <none>
replicaset.apps/my-replica-set1   3         3         3       24h   <none>


kubectl expose rs my-replica-set --name=lb-service2 --selector=app=rsexample --port 8000 --target-port=80 --type=LoadBalancer
service/lb-service2 exposed

kubectl get services
AME          TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
kubernetes    ClusterIP      10.96.0.1       <none>        443/TCP          29d
lb-service1   LoadBalancer   10.99.209.60    <pending>     8080:31694/TCP   38m
lb-service2   LoadBalancer   10.98.212.189   <pending>     8000:31566/TCP   28s

http://192.168.99.100:31566

-----------------------------------------------------------------------
Health Check Liveness Probes

kubernetes helps you to check health of your applicaiton specialy
in case it hangs
pods can be configured to periodically check an application's health from the outside world
you can specify a liveness probe for each container in the pod
kubernetes will periodically execute the probe and restart the container if probe fails
Here container restated means old is delted and new one is created.

1) HTTP GET
send request on containers IP , port and app path

2) TCP Socket
open TCP connection to the specific port to the container

3) EXEC Probe
execution probe
linux command
container file system 

kubectl create -f lp-probe1.yaml 
pod/lp-pod1 created

kubectl describe po lp-pod1

failureThreshold: 3 by default
Means to restart the container in case of 3 consective failure at liveness probe

periodSeconds: 10 by default
Means run this liveProbe after every 10 sec

successThreshold: 1
Reset failer threshold counter on first 1 successful response.

timeoutSeconds: 1
response within second else failure

initialDelaySeconds:15
will wait for 15 seconds to start first liveness probe (then it follow periodSeconds) as
it depends on application time require to start

------------------------Readiness Probes --------------------------------
The readiness probe is invoked persiodically and determines whether specific probe should receive 
client request or not
when a continer readiness probe returns success it indicates that the container is
ready to accept requests.
Access to users prohibted in case of issue

* Readiness probe mark as user not to reach the container in case of issue

Types

1)HTTP Get
IP address, port and path

10 seconds is by default time of readiness probe
kubectl create -f readiness-probe1.yaml
kubectl describe po readiness-pod1 



2) TCP Socket
conenction on port on the container


3) EXEC probe
linux command to issue on container file system


Best practice to use readiness probe along with liveness probe


















































































